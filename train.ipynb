{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN3tXZfrw5Ouqr2fidIYg/g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oiFAMNO8qpoS","colab_type":"code","outputId":"df36ff62-e676-4a8a-a3b0-83f9a175e7a3","executionInfo":{"status":"ok","timestamp":1589290218387,"user_tz":-480,"elapsed":31934,"user":{"displayName":"Mary Miller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp5B0q3ZMIgJqiyxVfsSNo_frsANO1M6xCbz24=s64","userId":"00211487820884275324"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","\n","import os\n","\n","path = \"/content/drive/九步/4\"\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","··········\n","fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['code',\n"," 'Assignment 04.pdf',\n"," 'lesson04AIV1.7 (1).pdf',\n"," 'mnist',\n"," 'model_params.pkl',\n"," 'train.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"nTeU_F2os4Vg","colab_type":"code","outputId":"de8e9cca-720b-4d90-dba9-5aecff4b0d21","executionInfo":{"status":"ok","timestamp":1589290298123,"user_tz":-480,"elapsed":28365,"user":{"displayName":"Mary Miller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp5B0q3ZMIgJqiyxVfsSNo_frsANO1M6xCbz24=s64","userId":"00211487820884275324"}},"colab":{"base_uri":"https://localhost:8080/","height":213}},"source":["import numpy as np\n","import keras as kr\n","import torch\n","import torch.utils.data as Data #将数据分批次需要用到\n","\n","#读取分目录 固定\n","def read_category():\n","  categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n","  categories = [x for x in categories]\n","  cat_to_id = dict(zip(categories, range(len(categories)))) \n","  return categories, cat_to_id\n","\n","def read_vocab(vocab_dir):\n","  with open(vocab_dir, 'r', encoding='utf-8', errors='ignore') as fp:\n","    words = [_.strip() for _ in fp.readlines()]\n","  word_to_word = dict(zip(words, range(len(words))))\n","  return words, word_to_word\n","\n","#将文件转换为id表示\n","def process_file(filename, word_to_id, cat_to_id, max_length=600):\n","    contents, labels = [], []\n","    with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n","        for line in f:\n","            try:\n","                label, content = line.strip().split('\\t')\n","                if content:\n","                    contents.append(list(content))\n","                    labels.append(label)\n","            except:\n","                pass\n","    data_id, label_id = [], []\n","    for i in range(len(contents)):\n","        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])#将每句话id化\n","        label_id.append(cat_to_id[labels[i]])#每句话对应的类别的id\n","    #\n","    # # 使用keras提供的pad_sequences来将文本pad为固定长度\n","    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, max_length)\n","    y_pad = kr.utils.to_categorical(label_id, num_classes=len(cat_to_id))  # 将标签转换为one-hot表示\n","    #\n","    return x_pad, y_pad\n"," \n","\n","categories, cat_to_id = read_category()\n","print(categories,cat_to_id)\n","\n","#获取训练文本中所有出现过的字及其所对应的id\n","words, word_to_id = read_vocab('./code/cnews/cnews.vocab.txt')\n","print(words)\n","print(word_to_id)\n","\n","#获取字数\n","vocab_size = len(words)\n","\n","# 获取训练数据每个字的id和对应标签的one-hot形式\n","x_train, y_train = process_file('./code/cnews/cnews.train.txt', word_to_id, cat_to_id, 600)\n","print('x_train=', x_train)\n","x_val, y_val = process_file('./code/cnews/cnews.val.txt', word_to_id, cat_to_id, 600)\n","\n","torch.manual_seed(33)\n","BATCH_SIZE=8\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐'] {'体育': 0, '财经': 1, '房产': 2, '家居': 3, '教育': 4, '科技': 5, '时尚': 6, '时政': 7, '游戏': 8, '娱乐': 9}\n","['<PAD>', '，', '的', '。', '一', '是', '在', '0', '有', '不', '了', '中', '1', '人', '大', '、', '国', '', '2', '这', '上', '为', '个', '“', '”', '年', '学', '时', '我', '地', '和', '以', '到', '出', '来', '会', '行', '发', '：', '对', '们', '要', '生', '家', '他', '能', '也', '业', '金', '3', '成', '可', '分', '多', '现', '5', '就', '场', '新', '后', '于', '下', '日', '经', '市', '前', '过', '方', '得', '作', '月', '最', '开', '房', '》', '《', '高', '9', '8', '.', '而', '比', '公', '4', '说', ')', '将', '(', '都', '资', 'e', '6', '基', '用', '面', '产', '还', '自', '者', '本', '之', '美', '很', '同', '', '7', '部', '进', '但', '主', '外', '动', '机', '元', '理', '加', 'a', '全', '与', '实', '影', '好', '小', '间', '其', '天', '定', '表', '力', '如', '次', '合', '长', 'o', '体', '价', 'i', '所', '内', '子', '目', '电', '-', '当', '度', '品', '看', '期', '关', '更', 'n', '等', '工', '然', '斯', '重', '些', '球', '此', '里', '利', '相', '情', '投', '点', '没', '因', '已', '三', '心', '特', '明', '位', '两', '法', '从', '入', '名', '万', '手', '计', '性', '事', '只', '样', '示', 'r', '种', '报', '海', '平', '数', '%', '第', '并', '色', '建', '据', '提', '商', '员', '通', '去', '民', 't', '着', '你', '片', '展', '道', '文', '演', '赛', '区', '交', '意', '政', '么', '今', '让', '起', '信', '化', '银', '记', '司', '北', '游', '科', '戏', '被', '格', '保', '及', '常', '物', '问', 's', '量', '制', '持', '果', '感', '设', '队', '无', '收', '正', '应', '？', '那', '活', '身', '式', '打', 'l', '系', '尔', '总', '京', 'A', '至', '己', '务', '受', '想', '星', '回', '留', '由', '网', '达', '认', '做', '题', '选', '费', '城', '增', '近', '华', '风', '非', '战', '布', '该', '接', '款', '项', 'S', '英', '女', '程', '导', '管', '二', '强', '证', '水', '代', '调', '少', '专', '型', '台', '给', '需', '规', '图', '周', '德', '解', '各', 'C', '向', '；', '别', '股', '东', '结', '或', '首', '士', '西', '安', '教', '变', '火', '节', '际', '任', '单', '先', '再', '观', '校', '显', '克', '组', '直', '装', '求', '才', '率', '较', '造', '使', '每', '考', '亿', '请', '流', '完', '拍', '取', '院', '线', '门', '放', '世', '住', '续', '联', '张', 'P', '息', '空', 'c', '研', '它', '十', '立', '原', '易', '整', '—', '术', '论', '消', '太', '知', '王', '质', '约', '客', '几', '配', '马', '统', '值', 'T', '头', '件', '带', '服', '她', '界', '指', 'D', '级', '企', '传', '老', '类', '始', '气', 'I', '户', '超', '育', '未', '具', 'm', '济', '低', '处', '技', '望', '把', 'M', '究', '什', '热', '推', '称', '购', '！', '季', '米', '光', '广', '份', '乐', '又', '获', '真', '觉', 'E', '玩', '形', '集', '备', '优', '领', '势', 'h', '楼', '准', '包', '像', '则', '难', '爱', '四', '申', 'B', 'd', '售', 'u', '快', '连', '话', '师', '告', '何', '视', '确', '深', '预', '局', '亚', '评', '票', '卡', '改', '候', '买', '况', '存', '支', '拉', '仅', '办', '注', '反', '环', '供', '角', '篮', '标', '转', '拿', '运', '参', '升', '众', 'O', '/', '创', '浪', '陈', '精', '号', '见', '助', '且', '土', '半', '议', '花', '步', '策', '南', '板', '居', '友', '越', '功', '构', '贷', '划', '模', '山', '融', '社', 'G', '决', '共', '案', 'g', '销', '走', '套', '路', '即', '言', '容', '均', '试', '积', '团', '府', '查', '条', '限', '引', '随', '择', '希', '口', '奇', '涨', '港', '盘', '象', '置', '林', '益', '效', '神', '极', '语', '复', '够', '阿', '币', '根', '州', '历', '采', '奖', '终', '适', 'N', '尼', '命', '段', '景', '险', '却', '失', '军', '权', '车', 'L', '剧', '速', '攻', '许', '足', '算', '清', '争', '响', '移', '红', '必', '幅', '额', 'y', '讯', '照', '源', '李', '验', '双', '刚', '另', '态', 'p', '致', '底', '除', '满', '击', '白', '五', '往', '喜', '财', '防', '境', '排', '百', '降', '远', '书', '习', '龙', '债', '钱', '断', '富', '曾', '测', '签', '举', '飞', '便', '介', '博', '牌', '虽', '料', '例', '边', '罗', '搭', '香', '委', '营', '器', 'R', '落', '跟', '列', '仍', '职', '尚', '阳', '监', '券', '儿', '尽', '衣', '负', '短', '找', '层', '黄', '艺', '域', '施', 'F', '离', '波', '胜', '兰', '古', '录', '黑', '素', '普', '史', '版', '摄', '官', '否', '石', '·', '站', 'w', '访', ',', '初', '细', '继', '责', '括', '卫', '露', '协', '轻', '维', '澳', '纪', '欢', '卖', '早', '绩', '穿', '孩', '按', '眼', '围', '男', '依', '宝', '控', 'b', '读', '状', '洲', '密', '差', '奥', '破', '块', '突', '…', '思', '画', '巴', '纳', '范', '映', '充', '媒', '室', 'H', '材', '字', '武', '跌', '春', '湖', '简', '担', '欧', '谈', '切', '兴', '刘', '彩', 'V', '稳', '待', '箭', '属', '声', '课', '透', '紧', '温', '绝', '园', '修', '农', '严', '减', '江', '讲', '航', '似', '独', '背', '夫', '甚', '志', '牛', '亮', '故', 'W', 'f', '汇', '义', '换', '货', '令', '饰', '招', '医', '占', '音', '群', '竞', '乎', '护', '姆', '席', '湾', '略', '央', '怎', '岁', '亲', '送', '补', '青', '索', '批', '核', '帮', '福', '伤', 'v', '昨', '念', '激', '陆', '危', '巨', '省', '宣', '般', '筑', 'k', '识', '守', '压', '错', '免', '店', '宅', '庭', '承', '雷', '云', '味', '典', '听', '笑', '登', '假', '审', '绍', '毕', '诉', '迷', '威', '谢', '练', '丽', '止', '微', '频', '净', '森', '拥', '须', '左', '印', '追', '秀', '托', '吴', '副', '疑', '千', '治', '冰', '右', '松', '晚', '皮', 'K', '佳', '夏', '呢', '魔', '缺', '编', '析', '钟', '刻', '遇', '停', '写', '付', '食', '织', '闻', '检', '礼', '惊', '莱', '余', '死', '雅', '善', '干', '愿', '爆', '某', '端', '探', '述', '吧', '执', '村', '租', '健', '阵', '律', '虑', '临', '冲', '盟', '六', '吸', '束', '射', '久', '馆', '暴', '折', '苏', '顿', '借', '宇', 'U', '病', '盛', '藏', '杰', '灵', '异', '察', '震', '退', '朋', '旅', '抢', '韩', '封', '轮', '康', '弹', '互', '伦', '败', '午', '河', '杀', '私', '镜', '扁', '潮', '幕', '旗', '党', '休', '八', '悉', '瑞', '逐', '征', '坚', '绿', '班', '迎', '吃', '母', '族', '税', '良', '丰', '训', '秘', '娱', '哈', '警', '伟', '您', '歌', '烈', '哪', '挑', '享', '肯', '凯', '顾', '杨', '丹', '雄', '键', '靠', '针', '木', '估', '届', '?', '嘉', '洛', '答', '七', '裙', '岛', '距', '刺', 'X', '趣', '养', '九', '座', '阶', '庆', '街', '释', ':', '扩', '洋', '永', '顺', '障', '盖', '勒', '遭', '铁', '笔', '启', '判', '倍', '豪', '吗', '杂', '哥', '纷', '婚', '秒', '斗', '犯', '剑', '沙', '派', '归', '操', '扮', '损', '仓', '延', '暖', '贵', '档', '载', '丝', '末', '截', '促', '竟', '油', '困', '泰', '梦', '播', '革', '络', '熟', 'Q', '顶', '酒', '础', '）', '倒', '著', '’', '麦', '章', '宁', '雪', '父', '授', '血', '裤', '静', '诺', '罚', '输', '润', '害', '船', '+', '掉', '蓝', '伊', '脑', '避', '尤', '赵', '缩', '综', '挥', '叫', '储', '镇', '寻', '怪', '鲁', '冠', '（', '努', '丁', '‘', '坛', '恩', '概', '扣', '旧', '趋', '培', '裁', '屋', 'J', '宽', '汉', '讨', '谁', '渐', '账', '涉', '岸', '胡', '毛', '锋', '迪', '幸', '偏', '秋', '菲', '码', '纯', '叶', '峰', '圣', '兵', '救', '暗', '鞋', '冬', '冷', '蒂', '侠', '董', '恐', '熊', '沃', '献', '惠', '圈', '朝', '询', '药', '智', '予', '既', '急', '吉', '曼', '赢', '姚', '替', '塔', '狂', '跳', '抗', '误', '触', '夜', '朗', '附', '坦', '慢', '励', '鱼', '含', '累', '若', '措', '怀', '贸', '雨', '草', '苦', '徐', '贴', '荣', '孙', '晓', '脚', '迅', '聚', '违', '厅', '募', '鲜', '潜', '圆', '餐', '坐', '仔', '勇', '软', '莫', '伯', '梅', '圳', '呈', '宾', '库', '凭', '掌', '俄', '焦', '漫', '灾', '曲', '佛', '怕', '谓', '劳', '贝', '廉', '符', '暂', '唯', '玉', '詹', '珍', '舒', '遗', 'x', '厚', '恒', '跑', '遍', '隆', '序', '词', '舞', '幻', '混', '粉', '灰', '田', '野', '赴', '宏', '邮', '硬', '宜', '帅', '架', '揭', '堂', '霸', '呼', '敌', '纽', '疗', '塞', '杜', '珠', '唐', '罪', '韦', '辛', '乡', '零', '迹', '固', '颜', '坏', '挂', '树', '戴', '翻', '帝', '闭', '川', '撞', 'z', '册', 'Y', '楚', '妈', '弱', '抵', '猫', '夺', '召', '埃', '腿', '筹', '握', '猛', '齐', '萨', '诚', '巧', '摆', '邀', '辉', '弃', '弟', '剩', '谋', '繁', '闲', '>', '途', '钢', '衡', '厂', '拟', '默', '弗', '恶', '沉', '锦', '署', '搞', '赞', '墙', '伴', '纹', '兽', '甲', '扬', '乔', '赶', '衫', '薪', '毫', '迈', '滑', '订', '禁', '散', '恋', '隐', '【', '】', '津', '缓', '泽', '牙', '腰', '旦', '童', '霍', '榜', '冯', '脱', '跃', '梁', '植', '肉', '仪', '醒', '郭', '晨', '掘', '涛', '\"', '详', '龄', '脸', '朱', '洁', '鼓', '姐', '侦', '仙', '洞', '桥', '骨', '枪', '晶', '洗', '亏', '句', '亡', '乱', '坡', '骑', '颗', '胸', '贡', '啊', '搜', '宗', '灯', '染', '奋', '返', '抓', '淡', '帽', '皇', '饭', '艾', '链', '纸', '摩', '拆', ']', '亦', '敏', '毒', '汽', '姜', '援', '渠', '芬', '诞', '敢', '甜', '伙', '轨', '敦', '曝', '庄', '凡', '陷', '恢', '欣', '[', '拓', '誉', '殊', '添', '咨', '壁', '拜', '荷', '县', '宫', '径', '蒙', '驻', '疯', '尝', '泡', '荐', '跨', '炒', '麻', '帕', '携', '辑', '屏', '乏', '缘', '尊', '彻', '邦', '督', '蔡', '贺', '虚', '浮', '拼', '劲', '贾', '虎', '盈', '卷', '★', '扰', '祖', '柔', '偿', '妙', '硕', 'Z', '闪', '兑', '兼', '扎', '郑', '黎', '鉴', '侧', '墅', '挺', '惯', '盗', '艳', '忙', '尾', '寸', '菜', '孤', '押', '床', '忘', '痛', '赏', '惜', '聊', '逊', '唱', '尺', '墨', '柏', '摇', '漂', '刊', '偶', '忆', '刀', '兄', '捕', '祝', '慎', '邓', '柜', '耶', '沟', '欲', '胞', '诸', '鸟', '患', '敬', '赚', '刷', '鹏', '迫', '姓', '紫', '迁', '抽', '宿', '妻', '矿', '颇', '鹿', '氛', '妇', '拒', '抱', '隔', '瓦', '塑', '羊', '泛', '慧', '窗', '绕', '籍', '孔', '址', '仿', '伍', '狼', '佩', '肩', '~', '冒', '灭', '忧', '衬', '稿', '耳', '谷', '酷', '递', '阅', '胀', '杭', '翰', '篇', '蕾', '霆', '汤', '尖', '娜', '恰', '淑', '袋', '覆', '描', '倾', '览', '迟', '魅', '蛋', '宋', '葛', '残', '烟', '振', '钻', '番', '贯', '喷', '靴', '氏', '沈', '炸', '奶', '舍', '铺', '芳', '杯', '寒', '箱', '赖', '谨', '君', '颁', '诗', '蜂', '玛', '赠', '宠', '桑', '薄', '潘', '忽', '液', '俗', '锁', '浓', '碰', '逃', '俱', '披', '懂', '寄', '燃', '坞', '沿', '袭', '奈', '允', '鹰', '曹', '骗', '横', '奢', '寓', '荡', '抛', '畅', '爵', '毁', '乘', '戈', '稍', '甘', '阻', '燕', '捷', '甄', '耗', '鬼', '涯', '墓', '壮', '赎', '虫', '爸', '旁', '阴', '惑', '耐', '宙', '御', '遥', '耀', '玲', '逆', '刑', '拖', '鸡', '沪', '仁', '偷', '岩', '池', '魂', '幽', '厦', '睡', '绪', '凌', '剪', '镑', '踪', '盾', '奏', '艰', '乌', '悲', '浙', '悬', '旋', '芝', '卢', '肖', '稀', '污', '缴', '堪', '拔', '袖', '堆', '厨', '杉', '裂', '侵', '聘', '碎', '胆', '磨', '役', '译', '洪', '烦', '妹', '怡', '捧', '狗', '忠', '挡', '尘', '唤', '肥', '卧', '嫌', '赤', '饮', '嘴', '辆', '闹', '浦', 'j', '阔', '猎', '浩', '昌', '撑', '沫', '娘', '谭', '逼', '症', '夹', '驾', '伏', '貌', '疾', '棒', '粒', '孟', '乳', '砍', '矶', '羽', '鼠', '栋', '猪', '绎', '粗', '腾', '昆', '忍', '涵', '泉', '爽', '郎', '绘', '桌', '碧', '彼', '尸', '浴', '搬', '喝', '凤', '×', '纠', '诱', '践', '惨', '坤', '踏', '昂', '挖', '悦', '泥', '谊', '肤', '奔', '碳', '谐', '烧', '瓶', '井', '莉', '俊', '哦', '妮', '犹', '巾', '庞', '宴', '睛', '幼', '&', '妆', '契', '舰', '矛', '铭', '扫', '陪', '壳', '酬', '弄', '浅', '徒', '填', '*', '兹', '摸', '夸', '拨', '炼', '抑', '愈', '晰', '琼', '伸', '梯', '茂', '烂', '堡', '驰', '戒', '捐', '孝', '－', '碑', '裕', '吨', '溢', '猜', '废', '赔', '磁', '煤', '吊', '琴', '掩', '旬', '纵', '姿', '菌', '碍', '怒', '秦', '怖', '串', '恤', '氧', '纺', '辨', '袜', '勤', '疫', '乃', '粮', '邻', '旺', '柯', '吹', '循', '琳', '勃', '爷', '瞬', '脉', '叹', '赋', '淘', '薇', '页', '陶', '漏', '蒋', '辈', '蓄', '毅', '雇', '巡', '欠', '牵', '奕', '插', '岗', '娃', '剂', '桂', '鸿', '暑', '崇', '挤', '郁', '赌', '胁', '茶', '膝', '涌', '廷', '憾', '鸣', '莎', '雕', '凉', '酸', '贤', '辞', '滚', '蝶', '槛', '啦', '渡', '锐', '玻', '拳', '赫', '翼', '茨', '厉', '攀', '•', '颖', '娇', '翔', '蛙', '蜜', '牢', '桃', '杆', '斑', '驱', '裸', '朵', '撤', '匹', '辅', '瓜', '枚', '械', '妖', '厘', '晋', '炮', '璃', '瘦', '哭', '飘', '伪', '侨', '框', '逾', '翠', '栏', '苑', '胶', '驶', '埋', '扶', '绒', '垃', '淇', '坑', '寿', '圾', '糕', '罕', '彭', '扭', '绑', '苗', '捉', '吕', '婴', '谱', '穷', '屡', '飙', '聪', '兆', '慈', '勿', '卓', '臣', '衰', '赁', '瓷', '腐', '斤', '弥', '=', '叠', '奉', '豆', '纱', '荒', '涂', '冻', '郊', '睐', '滩', '仇', '鼎', '祥', '轰', '盲', '～', '衷', '滞', '悠', '怨', '毯', '贫', '琪', '陨', '蛇', '泪', '肃', '侣', '臂', '陵', '莲', '垫', '猩', '椅', '劫', '皆', '尬', '脏', '丢', '尴', '铜', '靓', '盐', '傲', '膨', '彦', '旨', '婆', '辐', '贬', '疲', '艇', '棉', '泄', '妥', '胎', '滨', '喊', '擎', '柱', '翁', '狱', '馨', '魏', '糟', '腕', '悄', '妨', '砖', '履', '_', '哲', '谜', '虹', '吻', '炉', '纲', '竹', '劣', '闷', '纤', '泳', '咱', '漆', '凸', '夕', '俩', '脆', '饱', '藤', '贪', '亩', '猴', '辽', '漠', '塌', '丧', '孕', '疆', '轩', '玄', 'q', '斌', '擅', '僵', '汗', '挣', '峡', '袁', '衔', '弊', '凶', '痕', '巩', '邪', '勾', '寺', '朴', '迄', '侈', '呆', '抄', '豹', '斥', '掀', '彬', '躲', '裔', '罩', '辣', '盒', '啸', '莞', '丈', '钩', '缝', '肌', '炎', '狄', '糊', '帆', '橱', '倡', '媚', '笼', '磊', '凝', '慰', '渔', '割', '逢', '舟', '诈', '盼', '辩', '旭', '摊', '吓', '诊', '抬', '!', '垂', '魁', '逸', '髦', '彰', '艘', '屹', '轴', '蛮', '吁', '遵', '斜', '催', '姑', \"'\", '姻', '渤', '狮', '滋', '馈', '爬', '咖', '霞', '狠', '匪', '撼', '挫', '恨', '遮', '泼', '缀', '腻', '颠', '胖', '淀', '柳', '坠', '骂', '韵', '鲨', '湿', '耕', '啡', '敲', '撰', '翡', '穴', '扇', '疼', '蝠', '蛛', '俏', '醉', '糖', '煌', '鲸', '锡', '渴', '惧', '擦', '愤', '窄', '玫', '慕', '峻', '削', '舱', '抖', '抹', '腊', '炫', '摘', '歧', '楠', '帖', '熙', '寨', '捂', '穆', '丑', '兔', '殖', '慌', '嘛', '眠', '帐', '锻', '坎', '筐', '粹', '窃', '囊', '汶', '钉', '侯', '●', '羁', '戛', '□', '忌', '仰', '歇', '滴', '芯', '蝴', '瘾', '伐', '趁', '皱', '衍', '欺', '／', '溪', '逛', '吞', '悚', '蝙', '揽', '扑', '崩', '枝', '缠', '哨', '勘', '堵', '砸', '诠', '鼻', '珊', '瑜', '帘', '寂', '钞', '烨', '倩', '昔', '瑟', '磅', '骤', '嫁', '挪', '眉', '贿', '凰', '鲍', '淋', '俐', '鹅', '腹', '佣', '锤', '廊', '蓬', '骄', '悟', '屈', '呵', '删', '吐', '盆', '搏', '凳', '萎', '恼', '陌', '汪', '傅', '愉', '裹', '瞩', '褶', ';', '巫', '贼', '坊', '茅', '撒', '邱', '@', '雾', '筒', '咬', '齿', '矮', '斩', '鑫', '璇', '锅', '樟', '拐', '逻', '函', '苹', '婷', '喻', '旱', '仲', '瑰', '■', '惹', '慨', '窝', '悍', '讶', '悔', '膀', '晃', '颈', '讼', '凑', '亨', '葬', '睹', '叔', '崔', '蔓', '弯', '豫', '歉', '舆', '闯', '仕', '肿', '勋', '厌', '牲', '踝', '辰', '宪', '莹', '萧', '徽', '雀', '咏', '酿', '罢', '癌', '叛', '巢', '媛', '膜', '岳', '滥', '屠', '萍', '洒', '闫', '壤', '冕', '骚', '灌', '牧', '蜘', '橙', '垄', '肢', '弘', '牺', '嫩', '蹈', '龟', '肚', '炭', '汰', '傻', '芒', '阁', '螺', '桶', '壶', '胺', '绮', '黛', '#', '晕', '臀', '郡', '绵', '泊', '陕', '脂', '葡', '蔚', '粤', '秩', '抚', '秉', '婉', '雯', '睿', '羡', '奠', '驳', '蚁', '囤', '鳄', '疏', '肆', '殿', '逝', '廖', '洽', '谦', '钓', '挽', '棚', '棕', '卵', '豚', '澄', '拘', '沸', '薛', '顽', '谍', '禽', '氢', '邵', '辟', '苍', '砂', '劝', '剔', '舌', '丛', '萄', '郝', '％', '懒', '晤', '蒸', '啥', '伞', '湘', '茫', '辖', '盯', '拾', '尹', '蕴', '禅', '溃', '仗', '邹', '晒', '杠', '佐', '萌', '娥', '奎', '匆', '氰', '夷', '棋', '拯', '耍', '冈', '绸', '厕', '翟', '倪', '瞄', '碗', '筋', '祸', '庸', '暨', '岭', '竣', '诀', '巅', '栖', '⊙', '麟', '丙', '镶', '扔', '遣', '楂', '呀', '俪', '羞', '祭', '妩', '澜', '痴', '烛', '浏', '仑', '彗', '姬', '袍', '焰', '廓', '绣', '翅', '叙', '辱', '蓉', '刃', '戚', '乾', '怜', '阐', '辜', '雌', '辕', '臭', '狐', '敞', '渣', '荧', '脖', '帷', '甩', '胃', '搁', '乙', '顷', '晴', '瞻', '聂', '饼', '丘', '璐', '梨', '惩', '琦', '侃', '柴', '愁', '绚', '魄', '噪', '弈', '犀', '崛', '扯', '灿', '溯', '◆', '踢', '躺', '踩', '狭', '恭', '乖', '稻', '潭', '槽', '惕', '磋', '巷', '靡', '虐', '暮', '粘', '遏', '$', '铅', '浸', '绳', '刮', '愚', '炜', '镁', '哀', '逗', '勉', '酝', '芭', '浑', '畔', '沧', '嵌', '饲', '匠', '掏', '懈', '愧', '兜', '钗', '嫦', '咒', '屿', '骸', '叉', '渊', '绯', '霖', '躁', '漓', '匙', '昏', '弧', '蠢', '阱', '卜', '鸭', '脊', '庙', '渗', '屁', '浆', '韧', '肺', '熔', '鸦', '拦', '肠', '惟', '摔', '郅', '絮', '渝', '碌', 'é', '幢', '卸', '伽', '嘘', '擂', '龚', '腔', '婧', '烤', '硅', '纶', '矩', '诡', '昭', '娟', '霜', '翘', '燥', '冉', '摧', '碟', '篪', '汁', '犸', '玺', '甸', '窦', '铝', '晖', '蚀', '剖', '胚', '崖', '熬', '朔', '闵', '掠', '畏', '缅', '隅', '钥', '贩', '匿', '琢', '谅', '圻', '讽', '誓', '榄', '谣', '刹', '萝', '厄', '焕', '骼', '寥', '寞', '缎', '拷', '沦', '塘', '挨', '亥', '澡', '枯', '吵', '僧', '栈', '橘', '竭', '捡', '钮', '蔬', '髓', '谎', '橄', '溜', '睁', '撕', '沾', '缤', '茵', '拇', '寰', '罐', '佼', '屯', '竖', '殷', '崭', '潇', '犬', '．', '纬', '筛', '讳', '捞', '绽', '捏', '枫', '鞍', '琐', '卉', '涩', '铃', '肝', '唇', '腥', '卿', '瑶', '沛', '敛', '扛', '妍', '☆', '嘲', '弓', '坪', '窍', '觅', '奴', '凹', '佟', '缔', '蔽', '闸', '扳', '冤', '蚂', '梳', '骏', '爪', '哄', '丸', '喂', '镖', '湛', '篷', '娄', '柄', '逮', '蜥', '盎', '缪', '剥', '鹤', '蟹', '帜', '傍', '枕', '瀑', '徊', '徘', '阮', '俞', '炙', '芙', '靖', '哺', '挚', '袂', '炬', '肪', '禾', '硫', '汀', '珀', '钧', '烹', '彪', '肇', '噩', '隙', '桩', '锈', '礁', '嚣', '垒', '尿', '襟', '＋', '噬', '攒', '苛', '吼', '棍', '迭', '煞', '笨', '暇', '拢', '涡', '肘', '宰', '喇', '诛', '俭', '→', '钦', '菊', '藉', '坝', '卑', '樊', '锂', '铆', '亭', '虞', '咕', '棵', '俯', '铸', '斧', '饿', '盔', '彤', '掷', '梭', '淮', '瞒', '卦', '汹', '锣', '辙', '濒', '宵', '褐', '蜡', '耻', '橡', '咸', '乍', '乞', '缸', '膏', '垮', '鄂', '弦', '霉', '荫', '畴', '虾', '倦', '隧', '昧', '冥', '绅', '荆', '媳', '嫂', '浇', '昊', '瘤', '烫', '遂', '赘', '跻', '烷', '藻', '酱', '庚', '俨', '驼', '饥', '糙', '煮', '曙', '辄', '狙', '舶', '趟', '咋', '冀', '钾', '茜', '佑', '拱', '滤', '腺', '妃', '骁', '骷', '祈', '斐', '麒', '覃', '髅', '颓', '脾', '镂', '熠', '儒', '霄', '哑', '贞', '圃', '枢', '噱', '陋', '冶', '涅', '蒲', '耽', '喘', '杖', '窥', '隽', '姨', '哒', '|', '裴', '饶', '岚', '玮', '熏', '搅', '渲', '埔', '琛', '○', '─', '喧', '<', '℃', '踊', '拭', '肋', '耿', '厢', '邢', '镯', '捆', '株', '峥', '譬', '隶', '哇', '嫣', '葆', '屑', '璨', '绰', '孵', '沮', '帧', '揣', '歪', '奸', '瑚', '淹', '淳', '宛', '酶', '毋', '淫', '墟', '陡', '臃', '砚', '嘿', '啤', '嗅', '锯', '缚', '璀', '稽', '嬉', '茄', '佬', '栽', 'Ⅱ', '娅', '畜', '樱', '翩', '氨', '桦', '曦', '暧', '瞧', '鳌', '镀', '倘', '黯', '寡', '蚊', '葱', '惫', '幂', '烘', '惬', '椎', '飓', '抉', '妤', '溶', '昕', '媲', '沼', '轶', '闺', '煎', '饪', '滕', '耸', '＄', '聆', '氮', '罄', '菁', '庐', '蜀', '窘', '鲲', '姗', '窟', '醋', '雍', '禧', '岂', '灶', '棺', '晟', '赐', '艋', '珂', '瞎', '釉', '缆', '痒', '缉', '窑', '岐', '柬', '狸', '猿', '琅', '膊', '牟', '迥', '匀', '爹', '蜗', '婕', '嘟', '蹄', '菱', '骥', '拎', '恳', '骆', '炯', '渺', '茹', '炳', '诟', '赂', '哗', '笛', '颐', '趾', '歼', '∶', '泣', '陀', '蝉', '芦', '涿', '畸', '￥', '堕', '釜', '壹', '宕', '硝', '玖', '蓓', '瑕', '贱', '豁', '娶', '禄', '缭', '绷', '赝', '穗', '栗', '泌', '伺', '膑', '坍', '稚', '醛', '叮', '滔', '坟', '胳', '躯', '凿', '邬', '瞪', '驭', '葵', '棱', '瀚', '囚', '烁', '溅', '旷', '榻', '侍', '矢', '辗', '磷', '轿', '挠', '炽', '憋', '洼', '杏', '崎', '捍', '诫', '阎', '芽', '劈', '嘱', '吾', '谴', '沐', '梵', '鸥', '姥', '蜴', '珑', '檀', '棘', '鞭', '蜕', '逍', '堤', '惺', '桐', '戮', '沁', '孢', '癫', '跪', '侏', '嘻', '魑', '喉', '瘫', '醇', '肾', '喀', '栩', '骇', '瓣', '忑', '萃', '忐', '烯', '粪', '徙', '嗓', '邸', '榴', '凄', '诅', '蕉', '椒', '蹲', '妞', '芸', '嗯', '妒', '羚', '韬', '剃', '朽', '蝇', '秃', '恍', '亟', '鄢', '�', '憧', '褒', '牡', '妄', '汐', '阀', '扼', '遐', '蟒', '呕', '逅', '毙', '邂', '簇', '铮', '叭', '萱', '霾', '吝', '禺', '酋', '菇', '嗜', '襄', '蹊', '颤', '楷', '慑', '珏', '驯', '祷', '缇', '寇', '颂', '拽', '嫉', '憬', '氯', '飚', '褪', '氦', '灼', '眩', '悼', '螂', '俑', '咯', '铲', '砌', '疵', '兢', '跷', '枉', '袱', '晏', '皓', '澎', '晔', '僚', '・', '匈', '梓', '汛', '徕', '娴', '锥', '倚', '匮', '弩', '饽', '庇', '^', '厮', '荼', '匾', '沓', '恬', '瑾', '甫', '祺', '鳞', '孚', '眷', '孰', '坯', '孜', '迦', '莓', '拙', '矫', '僻', '啃', '蘑', '驴', '饺', '咽', '跋', '吟', '舵', '焚', '煽', '竿', '殴', '陇', '疤', '榆', '绊', '躬', '痪', '璧', '坷', '歹', '觑', '槟', '呐', '茸', '昱', '谬', '铨', '苞', '磕', '簿', '琥', '殆', '筝', '泻', '鞠', '缕', '窕', '窈', '檐', '兀', '掐', '趴', '瑙', '凛', '睦', '盏', '熄', '敷', '栅', '摒', '瞰', '潢', '喔', '佘', '蹿', '擒', '抒', '圭', '谙', '碘', '砥', '仆', '赃', '阪', '羹', '黏', '舅', '蹦', '鳍', '俘', '屉', '穹', '婪', '笈', '汲', '叨', '愣', '镍', '蛟', '挟', '撇', '咎', '寐', '°', '粥', '惮', '堰', '巍', '漩', '钙', '丐', '骋', '隋', '憨', '煜', '峨', '鹊', '毗', '慷', '酪', '哎', '烙', '\\\\', '棠', '娆', '慵', '挎', '莘', '煲', '惋', '咳', '翎', '尧', '寝', '斋', '昵', '蚕', '苯', '捣', '澈', '稠', '眨', '稣', '犷', '砷', '邃', '绞', '雏', '诧', '裘', '椭', '疟', '砭', '辫', '嘎', '呛', '涤', '篑', '榈', '岑', '戟', '颅', '铐', '咧', '蚓', '筷', '螃', '苟', '衅', '箍', '膺', '惶', '泵', '曳', '闽', '呱', '剽', '靶', '戳', '砝', '粟', '沽', '掺', '侥', '臻', '懵', '峙', '钵', '蝎', '狡', '弛', '昼', '琉', '碱', '哮', '奚', '伎', '蛰', '揪', '皙', '迸', '薯', '亢', '悖', '戎', '垦', '矜', '鸽', '鹦', '榕', '酣', '窒', '倔', '胯', '伶', '诵', '踵', '钊', '姊', '酌', '抨', '哟', '撩', '莅', 'μ', '拧', '®', '溉', '柠', '炅', '妓', '懿', '茧', '峭', '雁', '渎', '◎', '窖', '貂', '腩', '酥', '蒜', '舜', '蚯', '耘', '肴', '麓', '曜', '嚷', '韶', '娲', '缄', '嵩', '氓', '猬', '鹉', '娓', '敖', '诙', '筠', '刁', '匣', '矣', '邋', '柿', '※', '鱿', '紊', '淆', '皂', '竺', '鹜', '攘', '苓', '馅', '斓', '厥', '淌', '窜', '癖', '兮', '遢', '夭', '驹', '咪', '茎', '梗', '粽', '喋', '瑛', '屎', '鹭', '幔', '咀', '怠', '铧', '匡', '沌', '萤', '噢', '眈', '猖', '阙', '滇', '拌', '睫', '潍', '乒', '铂', '裱', '葫', '忡', '趸', '檬', '砺', '狩', '〈', '撬', '悸', '〉', '粱', '崽', '锏', '痊', '嚼', '瓢', '禹', '湮', '＝', '冗', '夯', '贰', '汝', '侮', '乓', '礴', '笃', '淤', '潞', '涎', '恪', '淼', '呦', '吆', '侄', '泓', '荔', '遴', '霓', '沂', '怯', '酵', '尉', '墩', '咫', '椰', '藩', '勺', '唾', '簧', '薰', '桓', '胧', '柒', '饕', '蠕', '钛', '蜒', '钰', '熹', '槌', '泾', '蜿', '埠', '疮', '谧', '挝', '笋', '瞿', '枣', '恺', '拂', '丫', '羌', '醍', '睾', '朦', '颚', '赈', '岌', '餮', '锷', '荟', '姝', '锄', '扉', '匕', '嘀', '芜', '铎', '萦', '暄', '秽', '栾', '啬', '菩', '糅', '鬃', '芋', '眸', '踞', '湃', '獗', '瀛', '裳', '奂', '纭', '罹', '焉', '阜', '氟', '茱', '瞅', '蛊', '昙', '篡', '蛤', '濮', '嵘', 'Ⅲ', '撮', '篱', '痞', '铿', '璞', '岔', '逞', '祀', '苇', '扒', '钝', '峪', '腱', '莽', '蚤', '溺', '瞠', '珐', '疚', '矗', '茬', '飒', '俺', '炖', '晾', '颊', '蒿', '橹', '彷', '咄', '泗', '掰', '笙', '砾', '卒', '沥', '宸', '馒', '嗽', '羲', '寅', '铠', '焱', '］', '螳', '铀', '漪', '遛', '荃', '浒', '姣', 'α', '诽', '聋', '猥', '丞', '［', '骰', '榨', '忱', '虱', '皿', '抠', '隼', '呗', '叱', '啼', '囱', '眯', '哉', '哼', '唉', '嚎', '憩', '嗒', '汾', '捅', '猾', '刨', '蟾', '鲶', '谤', '猝', '酯', '锌', '枭', '籽', '於', '犁', '曰', '垩', '唏', '诃', 'Ø', '①', '稼', '蜻', '唠', '™', '膛', '斟', '胤', 'è', '蟑', '轼', '痹', '叼', '猕', '蜓', '烬', '觎', '拣', '拗', '浚', '揍', '汕', '揉', '缮', '', '鄙', '剿', '泯', '祉', '璋', '虏', '婿', '莠', '捺', '蹬', '晦', '榷', '钒', '缨', '呜', '啪', '搀', '鹃', '狈', '觊', '瘟', '涓', '绌', '辍', '枷', '咤', '赣', '谛', '蔷', '腼', '亵', '浣', '〕', '霹', '饵', '瞥', '椋', '雳', '桔', '眶', '腆', '娩', '愫', '腮', '翌', '绢', '桨', '喙', '鞘', '旎', '〔', '惦', '凋', '澧', '憎', '惚', '烽', '跤', '昀', '殉', '怂', '邝', '涟', '芹', '魇', '羔', '贻', '祁', '赦', '殃', '蕊', '轲', '珉', '麾', '蟆', '驿', '咆', '蜍', '脐', '弋', '螈', '袒', '霁', '惰', '馥', '佯', '踹', '¾', '眺', '蓟', '祠', '渥', '掂', '臼', '蹭', '漾', '禀', '瘪', '喽', '涧', '懊', '鲟', '贮', '渍', '昴', '裆', '舔', 'ü', '摁', '琨', '谑', '咐', '钳', '缜', '昶', '摹', '帼', '焊', '毡', '‰', '锢', '邯', '②', '蛾', '髻', '秤', '肮', '蔑', '睽', '鬣', '茁', '涮', '町', '锚', '珞', '袄', '诩', '糜', '颌', '掮', '苔', '臆', '梧', '岖', '冽', '菠', '蔼', '黔', '诣', '镰', '膳', '殇', '漱', '躏', '垢', '坨', '腋', '鏖', '蹂', '泸', '铛', '札', '诘', '嗦', '玟', '偕', '妾', '嗡', '钚', '籁', '鹫', '搂', '澍', '隘', '卯', '迢', '馍', '遁', '袤', '炊', '溥', '嘶', '铤', '迂', '闰', '甭', '濡', '犒', '孽', '垣', '胫', '唬', 'Ａ', '胄', '嘈', '垡', '懦', '唧', '翱', '喃', '`', '跚', '晗', '棣', '荚', '幌', '⋯', '蹒', '殡', '犊', '蕙', '柚', '蛆', '茉', '煊', '冼', '遨', '涝', '胰', '哽', '馋', '睬', '馁', '鸠', '痫', '纣', '靳', '芥', '祛', '咂', '搓', '倭', '啄', '◇', '砰', '苷', '攫', '磺', '哆', '嗖', '浊', '榭', '恙', '涸', '霏', '扈', '獒', '搪', '酰', '鸳', '惭', '拄', '讧', '骅', '蜚', '鲤', '岱', '毓', '钠', '‧', '瞳', '潦', '藕', 'à', '芮', '脍', '濠', '疹', '偌', '啧', '镳', '嗣', '簸', '菅', '』', '狳', '阂', '『', '庶', '犰', '讹', '徨', '篆', '珥', '後', '鸯', '搡', '妊', '嫔', '梢', 'Ｇ', '掳', '瘩', '讥', '疙', '丕', '呃', '茗', '攸', '锲', '叩', '楔', '惘', '哩', '郦', '莺', '獭', '蹶', '衩', '↑', '夙', '虔', '嗔', '羸', '惴', '掣', '抡', '熨', '孪', '衙', '罡', '拈', '渭', 'Ｈ', '祟', '怅', '唆', '蔻', '恕', '狞', '愕', '啷', '燎', '瘠', '窿', '谩', '浜', '黝', '咔', '潺', 'Ⅶ', '涕', '纂', '箴', '遑', '靛', '藐', '煦', '踌', '邑', '▲', '咚', '魈', '婀', '湄', '筱', '鼬', '躇', '碾', '衢', '舛', '琶', '鸵', '泞', '轧', '拴', '撂', '攥', '忻', '√', '瘸', '佰', '铢', '翊', '裨', '腑', '漳', '胱', '馗', '讷', '徜', '灸', '跆', '祚', '樵', '珈', '―', '麂', '弑', '杞', '幄', '廿', '鳗', '鲑', '徉', '偎', '锵', '椁', '蛹', '冢', '娣', '侬', '笆', '③', '叽', '皑', '忏', '葩', '闳', '吱', '舷', '悴', '槐', '歆', '憔', '亘', 'Ⅰ', '蝌', '峦', '恣', '阑', '牒', '汞', '豉', '舸', '怵', '蝓', '蟠', '嗷', '帚', '盹', '褂', '蹴', '酗', '蚪', '噎', '灏', '蘸', '＆', '洱', '伫', '£', '甬', '〗', '↓', '掬', '〖', '淅', '贲', '懋', 'Ｃ', '蜷', '橇', '咙', '郸', '雹', '赓', '幺', '霰', '颦', '孱', '忒', '糗', '岷', '∩', '摞', '谚', '谲', '酮', '啮', '坂', '帛', '铱', '吒', '偃', '悯', '恻', '恿', 'β', 'Ｔ', '搔', '铯', '痰', '楹', '旖', '娠', '荥', '烩', '磐', '俚', '豌', '擞', '纫', '崴', '辘', '潸', '塾', '喳', '啻', '鎏', '狰', '壕', '颢', '嗤', '骛', '悻', '蛞', '嫡', '蚝', '焙', '糯', '缰', '鬓', '狒', '栎', '稔', '迩', '傀', '痘', '蔗', 'Ⅳ', '卞', '鹕', '蹩', '鹈', '孀', '瘀', '谕', '樾', '戾', '痼', '纾', '钿', '喱', '诬', '唔', '蛀', '钨', '滟', '楞', '拮', '栓', '粼', '骊', '壑', '濑', '仨', '￡', '嗨', '寮', '儡', '傣', '≠', '倜', '蕨', '吡', '霎', '疡', '泱', '羿', '俸', '瘙', '饬', '诿', '仝', '踉', '嗲', '柑', '纰', '腌', '嚏', '泠', '＞', '≤', '漕', '瓮', '聿', '腴', '喵', '卤', '箫', '樽', '褛', '惆', '渚', '羯', '摺', '酉', '挛', '氘', '傥', '笠', '幡', '诋', '鳖', '谒', '蚌', '炔', '屐', '奄', '谟', '羟', '飕', '鼹', '唰', '摈', '跄', '荀', '樨', '锆', '拚', '揄', '苜', '杵', '蓿', '盂', '麝', '镌', '揶', '阋', 'Ｏ', '鳃', '囡', '箔', '庾', '殓', '鸸', '蹋', '讪', '蝰', '脲', '阖', '稷', 'の', '褥', '胭', '铍', '桎', '疱', '潼', '绛', 'ä', '鲼', '诨', '梏', '逵', '铬', '痉', '鹋', '恃', '蔫', '钴', '铩', '皋', '§', 'Ｎ', '粕', '绫', '吭', '麽', '呻', '＊', '瞌', 'ン', '镣', '烊', '啕', '脓', '牍', '陲', '谘', '耷', '赅', '撷', '罔', '燮', '涣', '陂', '钜', '湍', '闾', '銮', '珙', '酩', '嚓', '邙', '怦', '铰', '忿', '＂', '祯', '榉', '刽', '伉', '蟀', '氚', '滦', '垠', '擘', '陛', '珩', '跺', '謦', '庖', '坻', '麋', '捶', '嗑', '褚', '焯', '湫', '僮', '桀', '荭', '蟋', '唁', '锹', '瘁', '咦', '熵', '榔', '胥', '腭', '缥', '桅', '嗝', '÷', '孺', '绉', '绥', '顼', '胛', 'É', '瞑', '砒', '颞', 'Ｂ', '脯', '噜', '荤', '吏', 'Ｅ', '囿', '骜', '捎', '沅', '瓯', '痍', '颛', '亳', '淄', '篝', '囔', '甥', '黠', '皖', '剁', '鞑', '秧', '娑', '谏', '吩', '赳', '撅', '鲈', '岫', '颧', '蹉', '岿', '谆', 'Ｄ', '跎', '漉', '佻', '\\xad', '仃', '²', '筵', '罂', '宦', '缈', '飨', '沣', '楣', '＜', '氩', '吮', '龈', '汩', '杳', '唳', '诏', '淞', '噔', '酚', '鼾', 'ó', '蛎', '锭', '鳕', 'イ', '碉', '蕲', '搐', '鄞', '臧', '皎', '诲', '蹑', '吠', '膘', '骡', '髋', '赡', '鹬', '艮', 'Ｖ', '楦', '＇', '嫖', '婶', '轫', '蛭', '€', '盥', '疣', '琵', '掴', '倬', '咿', '碴', '癣', '泔', '榫', '汨', 'ル', '蝾', '岬', '敝', '芊', '龛', '氙', '耦', '踱', '褓', '笺', '镉', '戊', '斡', '叁', '抿', '荞', '蚩', '袅', '婵', '徇', 'Ｆ', '仟', '皈', '逯', 'Ｓ', '彝', '讴', '醺', '柩', '炕', '淖', '揆', '綦', '畿', '嘞', '俾', '鲇', '狨', '芾', '蓦', '锶', '噤', '琏', '｜', '锰', '镪', '琮', '菏', '鲵', '掖', '璎', '荻', '韭', 'Ｐ', '鲔', '葳', 'ア', '嘹', '觞', '洙', '秣', '庵', '烃', '徵', '肽', '殒', '兖', '璜', '」', '龅', '啶', 'ç', '裥', '跛', '缂', '獠', '「', '袢', '莆', '豺', '勐', '妲', '磬', '浔', '睑', '鲱', '箩', '碜', '驮', '犄', '堑', '嬗', '蝮', '滢', '捱', '哌', '鹳', '圩', '叻', '锟', '栉', 'γ', '靼', '樘', '涔', '棂', '沱', '鸢', '馏', '苒', '颉', '桢', '隍', '牦', '瓒', '擢', '郇', '暌', '蜇', '劾', '≥', '捋', '扪', '邛', '蝗', '镭', '嵋', '桉', '捻', 'ö', 'ラ', '褴', '娼', '仄', '濂', '\\uf06c', '淬', '枳', '枸', '峋', '阉', '疽', '襁', '秸', '螨', '骞', '芷', '榛', '颀', '莨', '秆', '藓', '蕃', '悱', '旮', '窠', '溧', '嶙', 'ス', '}', '崂', '湎', '藜', '鸩', '钌', '椿', 'Ⅵ', '邡', '锗', '郴', '桁', '洵', '醴', 'Ｍ', '赭', '墒', '坳', '醚', 'ジ', '簪', '踮', '儆', '隈', 'Ｘ', '岘', '肛', '氪', '谶', '痤', '耆', '骧', '囹', '岙', '螭', '螯', '缱', '澹', '谔', '醪', '厝', '圄', '旯', '啖', '蜃', '鸾', '④', '梆', 'í', '硒', '绺', 'ê', '睇', '芑', '砧', '钤', '戬', '玷', '晌', '跗', '\\u200b', 'á', '嶂', '钺', '泷', '瓴', '痨', '耙', '±', '郗', '睢', '怆', '弼', 'Ⅷ', '挞', '纨', '┊', '孑', '俎', '戍', '″', '噼', '氤', '涪', '绗', '撵', '倌', '荏', '遽', '蜈', '＃', '箕', '竽', '钯', '韪', '貔', '凼', '箐', '垭', '枥', '貅']\n","{'<PAD>': 0, '，': 1, '的': 2, '。': 3, '一': 4, '是': 5, '在': 6, '0': 7, '有': 8, '不': 9, '了': 10, '中': 11, '1': 12, '人': 13, '大': 14, '、': 15, '国': 16, '': 3903, '2': 18, '这': 19, '上': 20, '为': 21, '个': 22, '“': 23, '”': 24, '年': 25, '学': 26, '时': 27, '我': 28, '地': 29, '和': 30, '以': 31, '到': 32, '出': 33, '来': 34, '会': 35, '行': 36, '发': 37, '：': 38, '对': 39, '们': 40, '要': 41, '生': 42, '家': 43, '他': 44, '能': 45, '也': 46, '业': 47, '金': 48, '3': 49, '成': 50, '可': 51, '分': 52, '多': 53, '现': 54, '5': 55, '就': 56, '场': 57, '新': 58, '后': 59, '于': 60, '下': 61, '日': 62, '经': 63, '市': 64, '前': 65, '过': 66, '方': 67, '得': 68, '作': 69, '月': 70, '最': 71, '开': 72, '房': 73, '》': 74, '《': 75, '高': 76, '9': 77, '8': 78, '.': 79, '而': 80, '比': 81, '公': 82, '4': 83, '说': 84, ')': 85, '将': 86, '(': 87, '都': 88, '资': 89, 'e': 90, '6': 91, '基': 92, '用': 93, '面': 94, '产': 95, '还': 96, '自': 97, '者': 98, '本': 99, '之': 100, '美': 101, '很': 102, '同': 103, '7': 105, '部': 106, '进': 107, '但': 108, '主': 109, '外': 110, '动': 111, '机': 112, '元': 113, '理': 114, '加': 115, 'a': 116, '全': 117, '与': 118, '实': 119, '影': 120, '好': 121, '小': 122, '间': 123, '其': 124, '天': 125, '定': 126, '表': 127, '力': 128, '如': 129, '次': 130, '合': 131, '长': 132, 'o': 133, '体': 134, '价': 135, 'i': 136, '所': 137, '内': 138, '子': 139, '目': 140, '电': 141, '-': 142, '当': 143, '度': 144, '品': 145, '看': 146, '期': 147, '关': 148, '更': 149, 'n': 150, '等': 151, '工': 152, '然': 153, '斯': 154, '重': 155, '些': 156, '球': 157, '此': 158, '里': 159, '利': 160, '相': 161, '情': 162, '投': 163, '点': 164, '没': 165, '因': 166, '已': 167, '三': 168, '心': 169, '特': 170, '明': 171, '位': 172, '两': 173, '法': 174, '从': 175, '入': 176, '名': 177, '万': 178, '手': 179, '计': 180, '性': 181, '事': 182, '只': 183, '样': 184, '示': 185, 'r': 186, '种': 187, '报': 188, '海': 189, '平': 190, '数': 191, '%': 192, '第': 193, '并': 194, '色': 195, '建': 196, '据': 197, '提': 198, '商': 199, '员': 200, '通': 201, '去': 202, '民': 203, 't': 204, '着': 205, '你': 206, '片': 207, '展': 208, '道': 209, '文': 210, '演': 211, '赛': 212, '区': 213, '交': 214, '意': 215, '政': 216, '么': 217, '今': 218, '让': 219, '起': 220, '信': 221, '化': 222, '银': 223, '记': 224, '司': 225, '北': 226, '游': 227, '科': 228, '戏': 229, '被': 230, '格': 231, '保': 232, '及': 233, '常': 234, '物': 235, '问': 236, 's': 237, '量': 238, '制': 239, '持': 240, '果': 241, '感': 242, '设': 243, '队': 244, '无': 245, '收': 246, '正': 247, '应': 248, '？': 249, '那': 250, '活': 251, '身': 252, '式': 253, '打': 254, 'l': 255, '系': 256, '尔': 257, '总': 258, '京': 259, 'A': 260, '至': 261, '己': 262, '务': 263, '受': 264, '想': 265, '星': 266, '回': 267, '留': 268, '由': 269, '网': 270, '达': 271, '认': 272, '做': 273, '题': 274, '选': 275, '费': 276, '城': 277, '增': 278, '近': 279, '华': 280, '风': 281, '非': 282, '战': 283, '布': 284, '该': 285, '接': 286, '款': 287, '项': 288, 'S': 289, '英': 290, '女': 291, '程': 292, '导': 293, '管': 294, '二': 295, '强': 296, '证': 297, '水': 298, '代': 299, '调': 300, '少': 301, '专': 302, '型': 303, '台': 304, '给': 305, '需': 306, '规': 307, '图': 308, '周': 309, '德': 310, '解': 311, '各': 312, 'C': 313, '向': 314, '；': 315, '别': 316, '股': 317, '东': 318, '结': 319, '或': 320, '首': 321, '士': 322, '西': 323, '安': 324, '教': 325, '变': 326, '火': 327, '节': 328, '际': 329, '任': 330, '单': 331, '先': 332, '再': 333, '观': 334, '校': 335, '显': 336, '克': 337, '组': 338, '直': 339, '装': 340, '求': 341, '才': 342, '率': 343, '较': 344, '造': 345, '使': 346, '每': 347, '考': 348, '亿': 349, '请': 350, '流': 351, '完': 352, '拍': 353, '取': 354, '院': 355, '线': 356, '门': 357, '放': 358, '世': 359, '住': 360, '续': 361, '联': 362, '张': 363, 'P': 364, '息': 365, '空': 366, 'c': 367, '研': 368, '它': 369, '十': 370, '立': 371, '原': 372, '易': 373, '整': 374, '—': 375, '术': 376, '论': 377, '消': 378, '太': 379, '知': 380, '王': 381, '质': 382, '约': 383, '客': 384, '几': 385, '配': 386, '马': 387, '统': 388, '值': 389, 'T': 390, '头': 391, '件': 392, '带': 393, '服': 394, '她': 395, '界': 396, '指': 397, 'D': 398, '级': 399, '企': 400, '传': 401, '老': 402, '类': 403, '始': 404, '气': 405, 'I': 406, '户': 407, '超': 408, '育': 409, '未': 410, '具': 411, 'm': 412, '济': 413, '低': 414, '处': 415, '技': 416, '望': 417, '把': 418, 'M': 419, '究': 420, '什': 421, '热': 422, '推': 423, '称': 424, '购': 425, '！': 426, '季': 427, '米': 428, '光': 429, '广': 430, '份': 431, '乐': 432, '又': 433, '获': 434, '真': 435, '觉': 436, 'E': 437, '玩': 438, '形': 439, '集': 440, '备': 441, '优': 442, '领': 443, '势': 444, 'h': 445, '楼': 446, '准': 447, '包': 448, '像': 449, '则': 450, '难': 451, '爱': 452, '四': 453, '申': 454, 'B': 455, 'd': 456, '售': 457, 'u': 458, '快': 459, '连': 460, '话': 461, '师': 462, '告': 463, '何': 464, '视': 465, '确': 466, '深': 467, '预': 468, '局': 469, '亚': 470, '评': 471, '票': 472, '卡': 473, '改': 474, '候': 475, '买': 476, '况': 477, '存': 478, '支': 479, '拉': 480, '仅': 481, '办': 482, '注': 483, '反': 484, '环': 485, '供': 486, '角': 487, '篮': 488, '标': 489, '转': 490, '拿': 491, '运': 492, '参': 493, '升': 494, '众': 495, 'O': 496, '/': 497, '创': 498, '浪': 499, '陈': 500, '精': 501, '号': 502, '见': 503, '助': 504, '且': 505, '土': 506, '半': 507, '议': 508, '花': 509, '步': 510, '策': 511, '南': 512, '板': 513, '居': 514, '友': 515, '越': 516, '功': 517, '构': 518, '贷': 519, '划': 520, '模': 521, '山': 522, '融': 523, '社': 524, 'G': 525, '决': 526, '共': 527, '案': 528, 'g': 529, '销': 530, '走': 531, '套': 532, '路': 533, '即': 534, '言': 535, '容': 536, '均': 537, '试': 538, '积': 539, '团': 540, '府': 541, '查': 542, '条': 543, '限': 544, '引': 545, '随': 546, '择': 547, '希': 548, '口': 549, '奇': 550, '涨': 551, '港': 552, '盘': 553, '象': 554, '置': 555, '林': 556, '益': 557, '效': 558, '神': 559, '极': 560, '语': 561, '复': 562, '够': 563, '阿': 564, '币': 565, '根': 566, '州': 567, '历': 568, '采': 569, '奖': 570, '终': 571, '适': 572, 'N': 573, '尼': 574, '命': 575, '段': 576, '景': 577, '险': 578, '却': 579, '失': 580, '军': 581, '权': 582, '车': 583, 'L': 584, '剧': 585, '速': 586, '攻': 587, '许': 588, '足': 589, '算': 590, '清': 591, '争': 592, '响': 593, '移': 594, '红': 595, '必': 596, '幅': 597, '额': 598, 'y': 599, '讯': 600, '照': 601, '源': 602, '李': 603, '验': 604, '双': 605, '刚': 606, '另': 607, '态': 608, 'p': 609, '致': 610, '底': 611, '除': 612, '满': 613, '击': 614, '白': 615, '五': 616, '往': 617, '喜': 618, '财': 619, '防': 620, '境': 621, '排': 622, '百': 623, '降': 624, '远': 625, '书': 626, '习': 627, '龙': 628, '债': 629, '钱': 630, '断': 631, '富': 632, '曾': 633, '测': 634, '签': 635, '举': 636, '飞': 637, '便': 638, '介': 639, '博': 640, '牌': 641, '虽': 642, '料': 643, '例': 644, '边': 645, '罗': 646, '搭': 647, '香': 648, '委': 649, '营': 650, '器': 651, 'R': 652, '落': 653, '跟': 654, '列': 655, '仍': 656, '职': 657, '尚': 658, '阳': 659, '监': 660, '券': 661, '儿': 662, '尽': 663, '衣': 664, '负': 665, '短': 666, '找': 667, '层': 668, '黄': 669, '艺': 670, '域': 671, '施': 672, 'F': 673, '离': 674, '波': 675, '胜': 676, '兰': 677, '古': 678, '录': 679, '黑': 680, '素': 681, '普': 682, '史': 683, '版': 684, '摄': 685, '官': 686, '否': 687, '石': 688, '·': 689, '站': 690, 'w': 691, '访': 692, ',': 693, '初': 694, '细': 695, '继': 696, '责': 697, '括': 698, '卫': 699, '露': 700, '协': 701, '轻': 702, '维': 703, '澳': 704, '纪': 705, '欢': 706, '卖': 707, '早': 708, '绩': 709, '穿': 710, '孩': 711, '按': 712, '眼': 713, '围': 714, '男': 715, '依': 716, '宝': 717, '控': 718, 'b': 719, '读': 720, '状': 721, '洲': 722, '密': 723, '差': 724, '奥': 725, '破': 726, '块': 727, '突': 728, '…': 729, '思': 730, '画': 731, '巴': 732, '纳': 733, '范': 734, '映': 735, '充': 736, '媒': 737, '室': 738, 'H': 739, '材': 740, '字': 741, '武': 742, '跌': 743, '春': 744, '湖': 745, '简': 746, '担': 747, '欧': 748, '谈': 749, '切': 750, '兴': 751, '刘': 752, '彩': 753, 'V': 754, '稳': 755, '待': 756, '箭': 757, '属': 758, '声': 759, '课': 760, '透': 761, '紧': 762, '温': 763, '绝': 764, '园': 765, '修': 766, '农': 767, '严': 768, '减': 769, '江': 770, '讲': 771, '航': 772, '似': 773, '独': 774, '背': 775, '夫': 776, '甚': 777, '志': 778, '牛': 779, '亮': 780, '故': 781, 'W': 782, 'f': 783, '汇': 784, '义': 785, '换': 786, '货': 787, '令': 788, '饰': 789, '招': 790, '医': 791, '占': 792, '音': 793, '群': 794, '竞': 795, '乎': 796, '护': 797, '姆': 798, '席': 799, '湾': 800, '略': 801, '央': 802, '怎': 803, '岁': 804, '亲': 805, '送': 806, '补': 807, '青': 808, '索': 809, '批': 810, '核': 811, '帮': 812, '福': 813, '伤': 814, 'v': 815, '昨': 816, '念': 817, '激': 818, '陆': 819, '危': 820, '巨': 821, '省': 822, '宣': 823, '般': 824, '筑': 825, 'k': 826, '识': 827, '守': 828, '压': 829, '错': 830, '免': 831, '店': 832, '宅': 833, '庭': 834, '承': 835, '雷': 836, '云': 837, '味': 838, '典': 839, '听': 840, '笑': 841, '登': 842, '假': 843, '审': 844, '绍': 845, '毕': 846, '诉': 847, '迷': 848, '威': 849, '谢': 850, '练': 851, '丽': 852, '止': 853, '微': 854, '频': 855, '净': 856, '森': 857, '拥': 858, '须': 859, '左': 860, '印': 861, '追': 862, '秀': 863, '托': 864, '吴': 865, '副': 866, '疑': 867, '千': 868, '治': 869, '冰': 870, '右': 871, '松': 872, '晚': 873, '皮': 874, 'K': 875, '佳': 876, '夏': 877, '呢': 878, '魔': 879, '缺': 880, '编': 881, '析': 882, '钟': 883, '刻': 884, '遇': 885, '停': 886, '写': 887, '付': 888, '食': 889, '织': 890, '闻': 891, '检': 892, '礼': 893, '惊': 894, '莱': 895, '余': 896, '死': 897, '雅': 898, '善': 899, '干': 900, '愿': 901, '爆': 902, '某': 903, '端': 904, '探': 905, '述': 906, '吧': 907, '执': 908, '村': 909, '租': 910, '健': 911, '阵': 912, '律': 913, '虑': 914, '临': 915, '冲': 916, '盟': 917, '六': 918, '吸': 919, '束': 920, '射': 921, '久': 922, '馆': 923, '暴': 924, '折': 925, '苏': 926, '顿': 927, '借': 928, '宇': 929, 'U': 930, '病': 931, '盛': 932, '藏': 933, '杰': 934, '灵': 935, '异': 936, '察': 937, '震': 938, '退': 939, '朋': 940, '旅': 941, '抢': 942, '韩': 943, '封': 944, '轮': 945, '康': 946, '弹': 947, '互': 948, '伦': 949, '败': 950, '午': 951, '河': 952, '杀': 953, '私': 954, '镜': 955, '扁': 956, '潮': 957, '幕': 958, '旗': 959, '党': 960, '休': 961, '八': 962, '悉': 963, '瑞': 964, '逐': 965, '征': 966, '坚': 967, '绿': 968, '班': 969, '迎': 970, '吃': 971, '母': 972, '族': 973, '税': 974, '良': 975, '丰': 976, '训': 977, '秘': 978, '娱': 979, '哈': 980, '警': 981, '伟': 982, '您': 983, '歌': 984, '烈': 985, '哪': 986, '挑': 987, '享': 988, '肯': 989, '凯': 990, '顾': 991, '杨': 992, '丹': 993, '雄': 994, '键': 995, '靠': 996, '针': 997, '木': 998, '估': 999, '届': 1000, '?': 1001, '嘉': 1002, '洛': 1003, '答': 1004, '七': 1005, '裙': 1006, '岛': 1007, '距': 1008, '刺': 1009, 'X': 1010, '趣': 1011, '养': 1012, '九': 1013, '座': 1014, '阶': 1015, '庆': 1016, '街': 1017, '释': 1018, ':': 1019, '扩': 1020, '洋': 1021, '永': 1022, '顺': 1023, '障': 1024, '盖': 1025, '勒': 1026, '遭': 1027, '铁': 1028, '笔': 1029, '启': 1030, '判': 1031, '倍': 1032, '豪': 1033, '吗': 1034, '杂': 1035, '哥': 1036, '纷': 1037, '婚': 1038, '秒': 1039, '斗': 1040, '犯': 1041, '剑': 1042, '沙': 1043, '派': 1044, '归': 1045, '操': 1046, '扮': 1047, '损': 1048, '仓': 1049, '延': 1050, '暖': 1051, '贵': 1052, '档': 1053, '载': 1054, '丝': 1055, '末': 1056, '截': 1057, '促': 1058, '竟': 1059, '油': 1060, '困': 1061, '泰': 1062, '梦': 1063, '播': 1064, '革': 1065, '络': 1066, '熟': 1067, 'Q': 1068, '顶': 1069, '酒': 1070, '础': 1071, '）': 1072, '倒': 1073, '著': 1074, '’': 1075, '麦': 1076, '章': 1077, '宁': 1078, '雪': 1079, '父': 1080, '授': 1081, '血': 1082, '裤': 1083, '静': 1084, '诺': 1085, '罚': 1086, '输': 1087, '润': 1088, '害': 1089, '船': 1090, '+': 1091, '掉': 1092, '蓝': 1093, '伊': 1094, '脑': 1095, '避': 1096, '尤': 1097, '赵': 1098, '缩': 1099, '综': 1100, '挥': 1101, '叫': 1102, '储': 1103, '镇': 1104, '寻': 1105, '怪': 1106, '鲁': 1107, '冠': 1108, '（': 1109, '努': 1110, '丁': 1111, '‘': 1112, '坛': 1113, '恩': 1114, '概': 1115, '扣': 1116, '旧': 1117, '趋': 1118, '培': 1119, '裁': 1120, '屋': 1121, 'J': 1122, '宽': 1123, '汉': 1124, '讨': 1125, '谁': 1126, '渐': 1127, '账': 1128, '涉': 1129, '岸': 1130, '胡': 1131, '毛': 1132, '锋': 1133, '迪': 1134, '幸': 1135, '偏': 1136, '秋': 1137, '菲': 1138, '码': 1139, '纯': 1140, '叶': 1141, '峰': 1142, '圣': 1143, '兵': 1144, '救': 1145, '暗': 1146, '鞋': 1147, '冬': 1148, '冷': 1149, '蒂': 1150, '侠': 1151, '董': 1152, '恐': 1153, '熊': 1154, '沃': 1155, '献': 1156, '惠': 1157, '圈': 1158, '朝': 1159, '询': 1160, '药': 1161, '智': 1162, '予': 1163, '既': 1164, '急': 1165, '吉': 1166, '曼': 1167, '赢': 1168, '姚': 1169, '替': 1170, '塔': 1171, '狂': 1172, '跳': 1173, '抗': 1174, '误': 1175, '触': 1176, '夜': 1177, '朗': 1178, '附': 1179, '坦': 1180, '慢': 1181, '励': 1182, '鱼': 1183, '含': 1184, '累': 1185, '若': 1186, '措': 1187, '怀': 1188, '贸': 1189, '雨': 1190, '草': 1191, '苦': 1192, '徐': 1193, '贴': 1194, '荣': 1195, '孙': 1196, '晓': 1197, '脚': 1198, '迅': 1199, '聚': 1200, '违': 1201, '厅': 1202, '募': 1203, '鲜': 1204, '潜': 1205, '圆': 1206, '餐': 1207, '坐': 1208, '仔': 1209, '勇': 1210, '软': 1211, '莫': 1212, '伯': 1213, '梅': 1214, '圳': 1215, '呈': 1216, '宾': 1217, '库': 1218, '凭': 1219, '掌': 1220, '俄': 1221, '焦': 1222, '漫': 1223, '灾': 1224, '曲': 1225, '佛': 1226, '怕': 1227, '谓': 1228, '劳': 1229, '贝': 1230, '廉': 1231, '符': 1232, '暂': 1233, '唯': 1234, '玉': 1235, '詹': 1236, '珍': 1237, '舒': 1238, '遗': 1239, 'x': 1240, '厚': 1241, '恒': 1242, '跑': 1243, '遍': 1244, '隆': 1245, '序': 1246, '词': 1247, '舞': 1248, '幻': 1249, '混': 1250, '粉': 1251, '灰': 1252, '田': 1253, '野': 1254, '赴': 1255, '宏': 1256, '邮': 1257, '硬': 1258, '宜': 1259, '帅': 1260, '架': 1261, '揭': 1262, '堂': 1263, '霸': 1264, '呼': 1265, '敌': 1266, '纽': 1267, '疗': 1268, '塞': 1269, '杜': 1270, '珠': 1271, '唐': 1272, '罪': 1273, '韦': 1274, '辛': 1275, '乡': 1276, '零': 1277, '迹': 1278, '固': 1279, '颜': 1280, '坏': 1281, '挂': 1282, '树': 1283, '戴': 1284, '翻': 1285, '帝': 1286, '闭': 1287, '川': 1288, '撞': 1289, 'z': 1290, '册': 1291, 'Y': 1292, '楚': 1293, '妈': 1294, '弱': 1295, '抵': 1296, '猫': 1297, '夺': 1298, '召': 1299, '埃': 1300, '腿': 1301, '筹': 1302, '握': 1303, '猛': 1304, '齐': 1305, '萨': 1306, '诚': 1307, '巧': 1308, '摆': 1309, '邀': 1310, '辉': 1311, '弃': 1312, '弟': 1313, '剩': 1314, '谋': 1315, '繁': 1316, '闲': 1317, '>': 1318, '途': 1319, '钢': 1320, '衡': 1321, '厂': 1322, '拟': 1323, '默': 1324, '弗': 1325, '恶': 1326, '沉': 1327, '锦': 1328, '署': 1329, '搞': 1330, '赞': 1331, '墙': 1332, '伴': 1333, '纹': 1334, '兽': 1335, '甲': 1336, '扬': 1337, '乔': 1338, '赶': 1339, '衫': 1340, '薪': 1341, '毫': 1342, '迈': 1343, '滑': 1344, '订': 1345, '禁': 1346, '散': 1347, '恋': 1348, '隐': 1349, '【': 1350, '】': 1351, '津': 1352, '缓': 1353, '泽': 1354, '牙': 1355, '腰': 1356, '旦': 1357, '童': 1358, '霍': 1359, '榜': 1360, '冯': 1361, '脱': 1362, '跃': 1363, '梁': 1364, '植': 1365, '肉': 1366, '仪': 1367, '醒': 1368, '郭': 1369, '晨': 1370, '掘': 1371, '涛': 1372, '\"': 1373, '详': 1374, '龄': 1375, '脸': 1376, '朱': 1377, '洁': 1378, '鼓': 1379, '姐': 1380, '侦': 1381, '仙': 1382, '洞': 1383, '桥': 1384, '骨': 1385, '枪': 1386, '晶': 1387, '洗': 1388, '亏': 1389, '句': 1390, '亡': 1391, '乱': 1392, '坡': 1393, '骑': 1394, '颗': 1395, '胸': 1396, '贡': 1397, '啊': 1398, '搜': 1399, '宗': 1400, '灯': 1401, '染': 1402, '奋': 1403, '返': 1404, '抓': 1405, '淡': 1406, '帽': 1407, '皇': 1408, '饭': 1409, '艾': 1410, '链': 1411, '纸': 1412, '摩': 1413, '拆': 1414, ']': 1415, '亦': 1416, '敏': 1417, '毒': 1418, '汽': 1419, '姜': 1420, '援': 1421, '渠': 1422, '芬': 1423, '诞': 1424, '敢': 1425, '甜': 1426, '伙': 1427, '轨': 1428, '敦': 1429, '曝': 1430, '庄': 1431, '凡': 1432, '陷': 1433, '恢': 1434, '欣': 1435, '[': 1436, '拓': 1437, '誉': 1438, '殊': 1439, '添': 1440, '咨': 1441, '壁': 1442, '拜': 1443, '荷': 1444, '县': 1445, '宫': 1446, '径': 1447, '蒙': 1448, '驻': 1449, '疯': 1450, '尝': 1451, '泡': 1452, '荐': 1453, '跨': 1454, '炒': 1455, '麻': 1456, '帕': 1457, '携': 1458, '辑': 1459, '屏': 1460, '乏': 1461, '缘': 1462, '尊': 1463, '彻': 1464, '邦': 1465, '督': 1466, '蔡': 1467, '贺': 1468, '虚': 1469, '浮': 1470, '拼': 1471, '劲': 1472, '贾': 1473, '虎': 1474, '盈': 1475, '卷': 1476, '★': 1477, '扰': 1478, '祖': 1479, '柔': 1480, '偿': 1481, '妙': 1482, '硕': 1483, 'Z': 1484, '闪': 1485, '兑': 1486, '兼': 1487, '扎': 1488, '郑': 1489, '黎': 1490, '鉴': 1491, '侧': 1492, '墅': 1493, '挺': 1494, '惯': 1495, '盗': 1496, '艳': 1497, '忙': 1498, '尾': 1499, '寸': 1500, '菜': 1501, '孤': 1502, '押': 1503, '床': 1504, '忘': 1505, '痛': 1506, '赏': 1507, '惜': 1508, '聊': 1509, '逊': 1510, '唱': 1511, '尺': 1512, '墨': 1513, '柏': 1514, '摇': 1515, '漂': 1516, '刊': 1517, '偶': 1518, '忆': 1519, '刀': 1520, '兄': 1521, '捕': 1522, '祝': 1523, '慎': 1524, '邓': 1525, '柜': 1526, '耶': 1527, '沟': 1528, '欲': 1529, '胞': 1530, '诸': 1531, '鸟': 1532, '患': 1533, '敬': 1534, '赚': 1535, '刷': 1536, '鹏': 1537, '迫': 1538, '姓': 1539, '紫': 1540, '迁': 1541, '抽': 1542, '宿': 1543, '妻': 1544, '矿': 1545, '颇': 1546, '鹿': 1547, '氛': 1548, '妇': 1549, '拒': 1550, '抱': 1551, '隔': 1552, '瓦': 1553, '塑': 1554, '羊': 1555, '泛': 1556, '慧': 1557, '窗': 1558, '绕': 1559, '籍': 1560, '孔': 1561, '址': 1562, '仿': 1563, '伍': 1564, '狼': 1565, '佩': 1566, '肩': 1567, '~': 1568, '冒': 1569, '灭': 1570, '忧': 1571, '衬': 1572, '稿': 1573, '耳': 1574, '谷': 1575, '酷': 1576, '递': 1577, '阅': 1578, '胀': 1579, '杭': 1580, '翰': 1581, '篇': 1582, '蕾': 1583, '霆': 1584, '汤': 1585, '尖': 1586, '娜': 1587, '恰': 1588, '淑': 1589, '袋': 1590, '覆': 1591, '描': 1592, '倾': 1593, '览': 1594, '迟': 1595, '魅': 1596, '蛋': 1597, '宋': 1598, '葛': 1599, '残': 1600, '烟': 1601, '振': 1602, '钻': 1603, '番': 1604, '贯': 1605, '喷': 1606, '靴': 1607, '氏': 1608, '沈': 1609, '炸': 1610, '奶': 1611, '舍': 1612, '铺': 1613, '芳': 1614, '杯': 1615, '寒': 1616, '箱': 1617, '赖': 1618, '谨': 1619, '君': 1620, '颁': 1621, '诗': 1622, '蜂': 1623, '玛': 1624, '赠': 1625, '宠': 1626, '桑': 1627, '薄': 1628, '潘': 1629, '忽': 1630, '液': 1631, '俗': 1632, '锁': 1633, '浓': 1634, '碰': 1635, '逃': 1636, '俱': 1637, '披': 1638, '懂': 1639, '寄': 1640, '燃': 1641, '坞': 1642, '沿': 1643, '袭': 1644, '奈': 1645, '允': 1646, '鹰': 1647, '曹': 1648, '骗': 1649, '横': 1650, '奢': 1651, '寓': 1652, '荡': 1653, '抛': 1654, '畅': 1655, '爵': 1656, '毁': 1657, '乘': 1658, '戈': 1659, '稍': 1660, '甘': 1661, '阻': 1662, '燕': 1663, '捷': 1664, '甄': 1665, '耗': 1666, '鬼': 1667, '涯': 1668, '墓': 1669, '壮': 1670, '赎': 1671, '虫': 1672, '爸': 1673, '旁': 1674, '阴': 1675, '惑': 1676, '耐': 1677, '宙': 1678, '御': 1679, '遥': 1680, '耀': 1681, '玲': 1682, '逆': 1683, '刑': 1684, '拖': 1685, '鸡': 1686, '沪': 1687, '仁': 1688, '偷': 1689, '岩': 1690, '池': 1691, '魂': 1692, '幽': 1693, '厦': 1694, '睡': 1695, '绪': 1696, '凌': 1697, '剪': 1698, '镑': 1699, '踪': 1700, '盾': 1701, '奏': 1702, '艰': 1703, '乌': 1704, '悲': 1705, '浙': 1706, '悬': 1707, '旋': 1708, '芝': 1709, '卢': 1710, '肖': 1711, '稀': 1712, '污': 1713, '缴': 1714, '堪': 1715, '拔': 1716, '袖': 1717, '堆': 1718, '厨': 1719, '杉': 1720, '裂': 1721, '侵': 1722, '聘': 1723, '碎': 1724, '胆': 1725, '磨': 1726, '役': 1727, '译': 1728, '洪': 1729, '烦': 1730, '妹': 1731, '怡': 1732, '捧': 1733, '狗': 1734, '忠': 1735, '挡': 1736, '尘': 1737, '唤': 1738, '肥': 1739, '卧': 1740, '嫌': 1741, '赤': 1742, '饮': 1743, '嘴': 1744, '辆': 1745, '闹': 1746, '浦': 1747, 'j': 1748, '阔': 1749, '猎': 1750, '浩': 1751, '昌': 1752, '撑': 1753, '沫': 1754, '娘': 1755, '谭': 1756, '逼': 1757, '症': 1758, '夹': 1759, '驾': 1760, '伏': 1761, '貌': 1762, '疾': 1763, '棒': 1764, '粒': 1765, '孟': 1766, '乳': 1767, '砍': 1768, '矶': 1769, '羽': 1770, '鼠': 1771, '栋': 1772, '猪': 1773, '绎': 1774, '粗': 1775, '腾': 1776, '昆': 1777, '忍': 1778, '涵': 1779, '泉': 1780, '爽': 1781, '郎': 1782, '绘': 1783, '桌': 1784, '碧': 1785, '彼': 1786, '尸': 1787, '浴': 1788, '搬': 1789, '喝': 1790, '凤': 1791, '×': 1792, '纠': 1793, '诱': 1794, '践': 1795, '惨': 1796, '坤': 1797, '踏': 1798, '昂': 1799, '挖': 1800, '悦': 1801, '泥': 1802, '谊': 1803, '肤': 1804, '奔': 1805, '碳': 1806, '谐': 1807, '烧': 1808, '瓶': 1809, '井': 1810, '莉': 1811, '俊': 1812, '哦': 1813, '妮': 1814, '犹': 1815, '巾': 1816, '庞': 1817, '宴': 1818, '睛': 1819, '幼': 1820, '&': 1821, '妆': 1822, '契': 1823, '舰': 1824, '矛': 1825, '铭': 1826, '扫': 1827, '陪': 1828, '壳': 1829, '酬': 1830, '弄': 1831, '浅': 1832, '徒': 1833, '填': 1834, '*': 1835, '兹': 1836, '摸': 1837, '夸': 1838, '拨': 1839, '炼': 1840, '抑': 1841, '愈': 1842, '晰': 1843, '琼': 1844, '伸': 1845, '梯': 1846, '茂': 1847, '烂': 1848, '堡': 1849, '驰': 1850, '戒': 1851, '捐': 1852, '孝': 1853, '－': 1854, '碑': 1855, '裕': 1856, '吨': 1857, '溢': 1858, '猜': 1859, '废': 1860, '赔': 1861, '磁': 1862, '煤': 1863, '吊': 1864, '琴': 1865, '掩': 1866, '旬': 1867, '纵': 1868, '姿': 1869, '菌': 1870, '碍': 1871, '怒': 1872, '秦': 1873, '怖': 1874, '串': 1875, '恤': 1876, '氧': 1877, '纺': 1878, '辨': 1879, '袜': 1880, '勤': 1881, '疫': 1882, '乃': 1883, '粮': 1884, '邻': 1885, '旺': 1886, '柯': 1887, '吹': 1888, '循': 1889, '琳': 1890, '勃': 1891, '爷': 1892, '瞬': 1893, '脉': 1894, '叹': 1895, '赋': 1896, '淘': 1897, '薇': 1898, '页': 1899, '陶': 1900, '漏': 1901, '蒋': 1902, '辈': 1903, '蓄': 1904, '毅': 1905, '雇': 1906, '巡': 1907, '欠': 1908, '牵': 1909, '奕': 1910, '插': 1911, '岗': 1912, '娃': 1913, '剂': 1914, '桂': 1915, '鸿': 1916, '暑': 1917, '崇': 1918, '挤': 1919, '郁': 1920, '赌': 1921, '胁': 1922, '茶': 1923, '膝': 1924, '涌': 1925, '廷': 1926, '憾': 1927, '鸣': 1928, '莎': 1929, '雕': 1930, '凉': 1931, '酸': 1932, '贤': 1933, '辞': 1934, '滚': 1935, '蝶': 1936, '槛': 1937, '啦': 1938, '渡': 1939, '锐': 1940, '玻': 1941, '拳': 1942, '赫': 1943, '翼': 1944, '茨': 1945, '厉': 1946, '攀': 1947, '•': 1948, '颖': 1949, '娇': 1950, '翔': 1951, '蛙': 1952, '蜜': 1953, '牢': 1954, '桃': 1955, '杆': 1956, '斑': 1957, '驱': 1958, '裸': 1959, '朵': 1960, '撤': 1961, '匹': 1962, '辅': 1963, '瓜': 1964, '枚': 1965, '械': 1966, '妖': 1967, '厘': 1968, '晋': 1969, '炮': 1970, '璃': 1971, '瘦': 1972, '哭': 1973, '飘': 1974, '伪': 1975, '侨': 1976, '框': 1977, '逾': 1978, '翠': 1979, '栏': 1980, '苑': 1981, '胶': 1982, '驶': 1983, '埋': 1984, '扶': 1985, '绒': 1986, '垃': 1987, '淇': 1988, '坑': 1989, '寿': 1990, '圾': 1991, '糕': 1992, '罕': 1993, '彭': 1994, '扭': 1995, '绑': 1996, '苗': 1997, '捉': 1998, '吕': 1999, '婴': 2000, '谱': 2001, '穷': 2002, '屡': 2003, '飙': 2004, '聪': 2005, '兆': 2006, '慈': 2007, '勿': 2008, '卓': 2009, '臣': 2010, '衰': 2011, '赁': 2012, '瓷': 2013, '腐': 2014, '斤': 2015, '弥': 2016, '=': 2017, '叠': 2018, '奉': 2019, '豆': 2020, '纱': 2021, '荒': 2022, '涂': 2023, '冻': 2024, '郊': 2025, '睐': 2026, '滩': 2027, '仇': 2028, '鼎': 2029, '祥': 2030, '轰': 2031, '盲': 2032, '～': 2033, '衷': 2034, '滞': 2035, '悠': 2036, '怨': 2037, '毯': 2038, '贫': 2039, '琪': 2040, '陨': 2041, '蛇': 2042, '泪': 2043, '肃': 2044, '侣': 2045, '臂': 2046, '陵': 2047, '莲': 2048, '垫': 2049, '猩': 2050, '椅': 2051, '劫': 2052, '皆': 2053, '尬': 2054, '脏': 2055, '丢': 2056, '尴': 2057, '铜': 2058, '靓': 2059, '盐': 2060, '傲': 2061, '膨': 2062, '彦': 2063, '旨': 2064, '婆': 2065, '辐': 2066, '贬': 2067, '疲': 2068, '艇': 2069, '棉': 2070, '泄': 2071, '妥': 2072, '胎': 2073, '滨': 2074, '喊': 2075, '擎': 2076, '柱': 2077, '翁': 2078, '狱': 2079, '馨': 2080, '魏': 2081, '糟': 2082, '腕': 2083, '悄': 2084, '妨': 2085, '砖': 2086, '履': 2087, '_': 2088, '哲': 2089, '谜': 2090, '虹': 2091, '吻': 2092, '炉': 2093, '纲': 2094, '竹': 2095, '劣': 2096, '闷': 2097, '纤': 2098, '泳': 2099, '咱': 2100, '漆': 2101, '凸': 2102, '夕': 2103, '俩': 2104, '脆': 2105, '饱': 2106, '藤': 2107, '贪': 2108, '亩': 2109, '猴': 2110, '辽': 2111, '漠': 2112, '塌': 2113, '丧': 2114, '孕': 2115, '疆': 2116, '轩': 2117, '玄': 2118, 'q': 2119, '斌': 2120, '擅': 2121, '僵': 2122, '汗': 2123, '挣': 2124, '峡': 2125, '袁': 2126, '衔': 2127, '弊': 2128, '凶': 2129, '痕': 2130, '巩': 2131, '邪': 2132, '勾': 2133, '寺': 2134, '朴': 2135, '迄': 2136, '侈': 2137, '呆': 2138, '抄': 2139, '豹': 2140, '斥': 2141, '掀': 2142, '彬': 2143, '躲': 2144, '裔': 2145, '罩': 2146, '辣': 2147, '盒': 2148, '啸': 2149, '莞': 2150, '丈': 2151, '钩': 2152, '缝': 2153, '肌': 2154, '炎': 2155, '狄': 2156, '糊': 2157, '帆': 2158, '橱': 2159, '倡': 2160, '媚': 2161, '笼': 2162, '磊': 2163, '凝': 2164, '慰': 2165, '渔': 2166, '割': 2167, '逢': 2168, '舟': 2169, '诈': 2170, '盼': 2171, '辩': 2172, '旭': 2173, '摊': 2174, '吓': 2175, '诊': 2176, '抬': 2177, '!': 2178, '垂': 2179, '魁': 2180, '逸': 2181, '髦': 2182, '彰': 2183, '艘': 2184, '屹': 2185, '轴': 2186, '蛮': 2187, '吁': 2188, '遵': 2189, '斜': 2190, '催': 2191, '姑': 2192, \"'\": 2193, '姻': 2194, '渤': 2195, '狮': 2196, '滋': 2197, '馈': 2198, '爬': 2199, '咖': 2200, '霞': 2201, '狠': 2202, '匪': 2203, '撼': 2204, '挫': 2205, '恨': 2206, '遮': 2207, '泼': 2208, '缀': 2209, '腻': 2210, '颠': 2211, '胖': 2212, '淀': 2213, '柳': 2214, '坠': 2215, '骂': 2216, '韵': 2217, '鲨': 2218, '湿': 2219, '耕': 2220, '啡': 2221, '敲': 2222, '撰': 2223, '翡': 2224, '穴': 2225, '扇': 2226, '疼': 2227, '蝠': 2228, '蛛': 2229, '俏': 2230, '醉': 2231, '糖': 2232, '煌': 2233, '鲸': 2234, '锡': 2235, '渴': 2236, '惧': 2237, '擦': 2238, '愤': 2239, '窄': 2240, '玫': 2241, '慕': 2242, '峻': 2243, '削': 2244, '舱': 2245, '抖': 2246, '抹': 2247, '腊': 2248, '炫': 2249, '摘': 2250, '歧': 2251, '楠': 2252, '帖': 2253, '熙': 2254, '寨': 2255, '捂': 2256, '穆': 2257, '丑': 2258, '兔': 2259, '殖': 2260, '慌': 2261, '嘛': 2262, '眠': 2263, '帐': 2264, '锻': 2265, '坎': 2266, '筐': 2267, '粹': 2268, '窃': 2269, '囊': 2270, '汶': 2271, '钉': 2272, '侯': 2273, '●': 2274, '羁': 2275, '戛': 2276, '□': 2277, '忌': 2278, '仰': 2279, '歇': 2280, '滴': 2281, '芯': 2282, '蝴': 2283, '瘾': 2284, '伐': 2285, '趁': 2286, '皱': 2287, '衍': 2288, '欺': 2289, '／': 2290, '溪': 2291, '逛': 2292, '吞': 2293, '悚': 2294, '蝙': 2295, '揽': 2296, '扑': 2297, '崩': 2298, '枝': 2299, '缠': 2300, '哨': 2301, '勘': 2302, '堵': 2303, '砸': 2304, '诠': 2305, '鼻': 2306, '珊': 2307, '瑜': 2308, '帘': 2309, '寂': 2310, '钞': 2311, '烨': 2312, '倩': 2313, '昔': 2314, '瑟': 2315, '磅': 2316, '骤': 2317, '嫁': 2318, '挪': 2319, '眉': 2320, '贿': 2321, '凰': 2322, '鲍': 2323, '淋': 2324, '俐': 2325, '鹅': 2326, '腹': 2327, '佣': 2328, '锤': 2329, '廊': 2330, '蓬': 2331, '骄': 2332, '悟': 2333, '屈': 2334, '呵': 2335, '删': 2336, '吐': 2337, '盆': 2338, '搏': 2339, '凳': 2340, '萎': 2341, '恼': 2342, '陌': 2343, '汪': 2344, '傅': 2345, '愉': 2346, '裹': 2347, '瞩': 2348, '褶': 2349, ';': 2350, '巫': 2351, '贼': 2352, '坊': 2353, '茅': 2354, '撒': 2355, '邱': 2356, '@': 2357, '雾': 2358, '筒': 2359, '咬': 2360, '齿': 2361, '矮': 2362, '斩': 2363, '鑫': 2364, '璇': 2365, '锅': 2366, '樟': 2367, '拐': 2368, '逻': 2369, '函': 2370, '苹': 2371, '婷': 2372, '喻': 2373, '旱': 2374, '仲': 2375, '瑰': 2376, '■': 2377, '惹': 2378, '慨': 2379, '窝': 2380, '悍': 2381, '讶': 2382, '悔': 2383, '膀': 2384, '晃': 2385, '颈': 2386, '讼': 2387, '凑': 2388, '亨': 2389, '葬': 2390, '睹': 2391, '叔': 2392, '崔': 2393, '蔓': 2394, '弯': 2395, '豫': 2396, '歉': 2397, '舆': 2398, '闯': 2399, '仕': 2400, '肿': 2401, '勋': 2402, '厌': 2403, '牲': 2404, '踝': 2405, '辰': 2406, '宪': 2407, '莹': 2408, '萧': 2409, '徽': 2410, '雀': 2411, '咏': 2412, '酿': 2413, '罢': 2414, '癌': 2415, '叛': 2416, '巢': 2417, '媛': 2418, '膜': 2419, '岳': 2420, '滥': 2421, '屠': 2422, '萍': 2423, '洒': 2424, '闫': 2425, '壤': 2426, '冕': 2427, '骚': 2428, '灌': 2429, '牧': 2430, '蜘': 2431, '橙': 2432, '垄': 2433, '肢': 2434, '弘': 2435, '牺': 2436, '嫩': 2437, '蹈': 2438, '龟': 2439, '肚': 2440, '炭': 2441, '汰': 2442, '傻': 2443, '芒': 2444, '阁': 2445, '螺': 2446, '桶': 2447, '壶': 2448, '胺': 2449, '绮': 2450, '黛': 2451, '#': 2452, '晕': 2453, '臀': 2454, '郡': 2455, '绵': 2456, '泊': 2457, '陕': 2458, '脂': 2459, '葡': 2460, '蔚': 2461, '粤': 2462, '秩': 2463, '抚': 2464, '秉': 2465, '婉': 2466, '雯': 2467, '睿': 2468, '羡': 2469, '奠': 2470, '驳': 2471, '蚁': 2472, '囤': 2473, '鳄': 2474, '疏': 2475, '肆': 2476, '殿': 2477, '逝': 2478, '廖': 2479, '洽': 2480, '谦': 2481, '钓': 2482, '挽': 2483, '棚': 2484, '棕': 2485, '卵': 2486, '豚': 2487, '澄': 2488, '拘': 2489, '沸': 2490, '薛': 2491, '顽': 2492, '谍': 2493, '禽': 2494, '氢': 2495, '邵': 2496, '辟': 2497, '苍': 2498, '砂': 2499, '劝': 2500, '剔': 2501, '舌': 2502, '丛': 2503, '萄': 2504, '郝': 2505, '％': 2506, '懒': 2507, '晤': 2508, '蒸': 2509, '啥': 2510, '伞': 2511, '湘': 2512, '茫': 2513, '辖': 2514, '盯': 2515, '拾': 2516, '尹': 2517, '蕴': 2518, '禅': 2519, '溃': 2520, '仗': 2521, '邹': 2522, '晒': 2523, '杠': 2524, '佐': 2525, '萌': 2526, '娥': 2527, '奎': 2528, '匆': 2529, '氰': 2530, '夷': 2531, '棋': 2532, '拯': 2533, '耍': 2534, '冈': 2535, '绸': 2536, '厕': 2537, '翟': 2538, '倪': 2539, '瞄': 2540, '碗': 2541, '筋': 2542, '祸': 2543, '庸': 2544, '暨': 2545, '岭': 2546, '竣': 2547, '诀': 2548, '巅': 2549, '栖': 2550, '⊙': 2551, '麟': 2552, '丙': 2553, '镶': 2554, '扔': 2555, '遣': 2556, '楂': 2557, '呀': 2558, '俪': 2559, '羞': 2560, '祭': 2561, '妩': 2562, '澜': 2563, '痴': 2564, '烛': 2565, '浏': 2566, '仑': 2567, '彗': 2568, '姬': 2569, '袍': 2570, '焰': 2571, '廓': 2572, '绣': 2573, '翅': 2574, '叙': 2575, '辱': 2576, '蓉': 2577, '刃': 2578, '戚': 2579, '乾': 2580, '怜': 2581, '阐': 2582, '辜': 2583, '雌': 2584, '辕': 2585, '臭': 2586, '狐': 2587, '敞': 2588, '渣': 2589, '荧': 2590, '脖': 2591, '帷': 2592, '甩': 2593, '胃': 2594, '搁': 2595, '乙': 2596, '顷': 2597, '晴': 2598, '瞻': 2599, '聂': 2600, '饼': 2601, '丘': 2602, '璐': 2603, '梨': 2604, '惩': 2605, '琦': 2606, '侃': 2607, '柴': 2608, '愁': 2609, '绚': 2610, '魄': 2611, '噪': 2612, '弈': 2613, '犀': 2614, '崛': 2615, '扯': 2616, '灿': 2617, '溯': 2618, '◆': 2619, '踢': 2620, '躺': 2621, '踩': 2622, '狭': 2623, '恭': 2624, '乖': 2625, '稻': 2626, '潭': 2627, '槽': 2628, '惕': 2629, '磋': 2630, '巷': 2631, '靡': 2632, '虐': 2633, '暮': 2634, '粘': 2635, '遏': 2636, '$': 2637, '铅': 2638, '浸': 2639, '绳': 2640, '刮': 2641, '愚': 2642, '炜': 2643, '镁': 2644, '哀': 2645, '逗': 2646, '勉': 2647, '酝': 2648, '芭': 2649, '浑': 2650, '畔': 2651, '沧': 2652, '嵌': 2653, '饲': 2654, '匠': 2655, '掏': 2656, '懈': 2657, '愧': 2658, '兜': 2659, '钗': 2660, '嫦': 2661, '咒': 2662, '屿': 2663, '骸': 2664, '叉': 2665, '渊': 2666, '绯': 2667, '霖': 2668, '躁': 2669, '漓': 2670, '匙': 2671, '昏': 2672, '弧': 2673, '蠢': 2674, '阱': 2675, '卜': 2676, '鸭': 2677, '脊': 2678, '庙': 2679, '渗': 2680, '屁': 2681, '浆': 2682, '韧': 2683, '肺': 2684, '熔': 2685, '鸦': 2686, '拦': 2687, '肠': 2688, '惟': 2689, '摔': 2690, '郅': 2691, '絮': 2692, '渝': 2693, '碌': 2694, 'é': 2695, '幢': 2696, '卸': 2697, '伽': 2698, '嘘': 2699, '擂': 2700, '龚': 2701, '腔': 2702, '婧': 2703, '烤': 2704, '硅': 2705, '纶': 2706, '矩': 2707, '诡': 2708, '昭': 2709, '娟': 2710, '霜': 2711, '翘': 2712, '燥': 2713, '冉': 2714, '摧': 2715, '碟': 2716, '篪': 2717, '汁': 2718, '犸': 2719, '玺': 2720, '甸': 2721, '窦': 2722, '铝': 2723, '晖': 2724, '蚀': 2725, '剖': 2726, '胚': 2727, '崖': 2728, '熬': 2729, '朔': 2730, '闵': 2731, '掠': 2732, '畏': 2733, '缅': 2734, '隅': 2735, '钥': 2736, '贩': 2737, '匿': 2738, '琢': 2739, '谅': 2740, '圻': 2741, '讽': 2742, '誓': 2743, '榄': 2744, '谣': 2745, '刹': 2746, '萝': 2747, '厄': 2748, '焕': 2749, '骼': 2750, '寥': 2751, '寞': 2752, '缎': 2753, '拷': 2754, '沦': 2755, '塘': 2756, '挨': 2757, '亥': 2758, '澡': 2759, '枯': 2760, '吵': 2761, '僧': 2762, '栈': 2763, '橘': 2764, '竭': 2765, '捡': 2766, '钮': 2767, '蔬': 2768, '髓': 2769, '谎': 2770, '橄': 2771, '溜': 2772, '睁': 2773, '撕': 2774, '沾': 2775, '缤': 2776, '茵': 2777, '拇': 2778, '寰': 2779, '罐': 2780, '佼': 2781, '屯': 2782, '竖': 2783, '殷': 2784, '崭': 2785, '潇': 2786, '犬': 2787, '．': 2788, '纬': 2789, '筛': 2790, '讳': 2791, '捞': 2792, '绽': 2793, '捏': 2794, '枫': 2795, '鞍': 2796, '琐': 2797, '卉': 2798, '涩': 2799, '铃': 2800, '肝': 2801, '唇': 2802, '腥': 2803, '卿': 2804, '瑶': 2805, '沛': 2806, '敛': 2807, '扛': 2808, '妍': 2809, '☆': 2810, '嘲': 2811, '弓': 2812, '坪': 2813, '窍': 2814, '觅': 2815, '奴': 2816, '凹': 2817, '佟': 2818, '缔': 2819, '蔽': 2820, '闸': 2821, '扳': 2822, '冤': 2823, '蚂': 2824, '梳': 2825, '骏': 2826, '爪': 2827, '哄': 2828, '丸': 2829, '喂': 2830, '镖': 2831, '湛': 2832, '篷': 2833, '娄': 2834, '柄': 2835, '逮': 2836, '蜥': 2837, '盎': 2838, '缪': 2839, '剥': 2840, '鹤': 2841, '蟹': 2842, '帜': 2843, '傍': 2844, '枕': 2845, '瀑': 2846, '徊': 2847, '徘': 2848, '阮': 2849, '俞': 2850, '炙': 2851, '芙': 2852, '靖': 2853, '哺': 2854, '挚': 2855, '袂': 2856, '炬': 2857, '肪': 2858, '禾': 2859, '硫': 2860, '汀': 2861, '珀': 2862, '钧': 2863, '烹': 2864, '彪': 2865, '肇': 2866, '噩': 2867, '隙': 2868, '桩': 2869, '锈': 2870, '礁': 2871, '嚣': 2872, '垒': 2873, '尿': 2874, '襟': 2875, '＋': 2876, '噬': 2877, '攒': 2878, '苛': 2879, '吼': 2880, '棍': 2881, '迭': 2882, '煞': 2883, '笨': 2884, '暇': 2885, '拢': 2886, '涡': 2887, '肘': 2888, '宰': 2889, '喇': 2890, '诛': 2891, '俭': 2892, '→': 2893, '钦': 2894, '菊': 2895, '藉': 2896, '坝': 2897, '卑': 2898, '樊': 2899, '锂': 2900, '铆': 2901, '亭': 2902, '虞': 2903, '咕': 2904, '棵': 2905, '俯': 2906, '铸': 2907, '斧': 2908, '饿': 2909, '盔': 2910, '彤': 2911, '掷': 2912, '梭': 2913, '淮': 2914, '瞒': 2915, '卦': 2916, '汹': 2917, '锣': 2918, '辙': 2919, '濒': 2920, '宵': 2921, '褐': 2922, '蜡': 2923, '耻': 2924, '橡': 2925, '咸': 2926, '乍': 2927, '乞': 2928, '缸': 2929, '膏': 2930, '垮': 2931, '鄂': 2932, '弦': 2933, '霉': 2934, '荫': 2935, '畴': 2936, '虾': 2937, '倦': 2938, '隧': 2939, '昧': 2940, '冥': 2941, '绅': 2942, '荆': 2943, '媳': 2944, '嫂': 2945, '浇': 2946, '昊': 2947, '瘤': 2948, '烫': 2949, '遂': 2950, '赘': 2951, '跻': 2952, '烷': 2953, '藻': 2954, '酱': 2955, '庚': 2956, '俨': 2957, '驼': 2958, '饥': 2959, '糙': 2960, '煮': 2961, '曙': 2962, '辄': 2963, '狙': 2964, '舶': 2965, '趟': 2966, '咋': 2967, '冀': 2968, '钾': 2969, '茜': 2970, '佑': 2971, '拱': 2972, '滤': 2973, '腺': 2974, '妃': 2975, '骁': 2976, '骷': 2977, '祈': 2978, '斐': 2979, '麒': 2980, '覃': 2981, '髅': 2982, '颓': 2983, '脾': 2984, '镂': 2985, '熠': 2986, '儒': 2987, '霄': 2988, '哑': 2989, '贞': 2990, '圃': 2991, '枢': 2992, '噱': 2993, '陋': 2994, '冶': 2995, '涅': 2996, '蒲': 2997, '耽': 2998, '喘': 2999, '杖': 3000, '窥': 3001, '隽': 3002, '姨': 3003, '哒': 3004, '|': 3005, '裴': 3006, '饶': 3007, '岚': 3008, '玮': 3009, '熏': 3010, '搅': 3011, '渲': 3012, '埔': 3013, '琛': 3014, '○': 3015, '─': 3016, '喧': 3017, '<': 3018, '℃': 3019, '踊': 3020, '拭': 3021, '肋': 3022, '耿': 3023, '厢': 3024, '邢': 3025, '镯': 3026, '捆': 3027, '株': 3028, '峥': 3029, '譬': 3030, '隶': 3031, '哇': 3032, '嫣': 3033, '葆': 3034, '屑': 3035, '璨': 3036, '绰': 3037, '孵': 3038, '沮': 3039, '帧': 3040, '揣': 3041, '歪': 3042, '奸': 3043, '瑚': 3044, '淹': 3045, '淳': 3046, '宛': 3047, '酶': 3048, '毋': 3049, '淫': 3050, '墟': 3051, '陡': 3052, '臃': 3053, '砚': 3054, '嘿': 3055, '啤': 3056, '嗅': 3057, '锯': 3058, '缚': 3059, '璀': 3060, '稽': 3061, '嬉': 3062, '茄': 3063, '佬': 3064, '栽': 3065, 'Ⅱ': 3066, '娅': 3067, '畜': 3068, '樱': 3069, '翩': 3070, '氨': 3071, '桦': 3072, '曦': 3073, '暧': 3074, '瞧': 3075, '鳌': 3076, '镀': 3077, '倘': 3078, '黯': 3079, '寡': 3080, '蚊': 3081, '葱': 3082, '惫': 3083, '幂': 3084, '烘': 3085, '惬': 3086, '椎': 3087, '飓': 3088, '抉': 3089, '妤': 3090, '溶': 3091, '昕': 3092, '媲': 3093, '沼': 3094, '轶': 3095, '闺': 3096, '煎': 3097, '饪': 3098, '滕': 3099, '耸': 3100, '＄': 3101, '聆': 3102, '氮': 3103, '罄': 3104, '菁': 3105, '庐': 3106, '蜀': 3107, '窘': 3108, '鲲': 3109, '姗': 3110, '窟': 3111, '醋': 3112, '雍': 3113, '禧': 3114, '岂': 3115, '灶': 3116, '棺': 3117, '晟': 3118, '赐': 3119, '艋': 3120, '珂': 3121, '瞎': 3122, '釉': 3123, '缆': 3124, '痒': 3125, '缉': 3126, '窑': 3127, '岐': 3128, '柬': 3129, '狸': 3130, '猿': 3131, '琅': 3132, '膊': 3133, '牟': 3134, '迥': 3135, '匀': 3136, '爹': 3137, '蜗': 3138, '婕': 3139, '嘟': 3140, '蹄': 3141, '菱': 3142, '骥': 3143, '拎': 3144, '恳': 3145, '骆': 3146, '炯': 3147, '渺': 3148, '茹': 3149, '炳': 3150, '诟': 3151, '赂': 3152, '哗': 3153, '笛': 3154, '颐': 3155, '趾': 3156, '歼': 3157, '∶': 3158, '泣': 3159, '陀': 3160, '蝉': 3161, '芦': 3162, '涿': 3163, '畸': 3164, '￥': 3165, '堕': 3166, '釜': 3167, '壹': 3168, '宕': 3169, '硝': 3170, '玖': 3171, '蓓': 3172, '瑕': 3173, '贱': 3174, '豁': 3175, '娶': 3176, '禄': 3177, '缭': 3178, '绷': 3179, '赝': 3180, '穗': 3181, '栗': 3182, '泌': 3183, '伺': 3184, '膑': 3185, '坍': 3186, '稚': 3187, '醛': 3188, '叮': 3189, '滔': 3190, '坟': 3191, '胳': 3192, '躯': 3193, '凿': 3194, '邬': 3195, '瞪': 3196, '驭': 3197, '葵': 3198, '棱': 3199, '瀚': 3200, '囚': 3201, '烁': 3202, '溅': 3203, '旷': 3204, '榻': 3205, '侍': 3206, '矢': 3207, '辗': 3208, '磷': 3209, '轿': 3210, '挠': 3211, '炽': 3212, '憋': 3213, '洼': 3214, '杏': 3215, '崎': 3216, '捍': 3217, '诫': 3218, '阎': 3219, '芽': 3220, '劈': 3221, '嘱': 3222, '吾': 3223, '谴': 3224, '沐': 3225, '梵': 3226, '鸥': 3227, '姥': 3228, '蜴': 3229, '珑': 3230, '檀': 3231, '棘': 3232, '鞭': 3233, '蜕': 3234, '逍': 3235, '堤': 3236, '惺': 3237, '桐': 3238, '戮': 3239, '沁': 3240, '孢': 3241, '癫': 3242, '跪': 3243, '侏': 3244, '嘻': 3245, '魑': 3246, '喉': 3247, '瘫': 3248, '醇': 3249, '肾': 3250, '喀': 3251, '栩': 3252, '骇': 3253, '瓣': 3254, '忑': 3255, '萃': 3256, '忐': 3257, '烯': 3258, '粪': 3259, '徙': 3260, '嗓': 3261, '邸': 3262, '榴': 3263, '凄': 3264, '诅': 3265, '蕉': 3266, '椒': 3267, '蹲': 3268, '妞': 3269, '芸': 3270, '嗯': 3271, '妒': 3272, '羚': 3273, '韬': 3274, '剃': 3275, '朽': 3276, '蝇': 3277, '秃': 3278, '恍': 3279, '亟': 3280, '鄢': 3281, '�': 3282, '憧': 3283, '褒': 3284, '牡': 3285, '妄': 3286, '汐': 3287, '阀': 3288, '扼': 3289, '遐': 3290, '蟒': 3291, '呕': 3292, '逅': 3293, '毙': 3294, '邂': 3295, '簇': 3296, '铮': 3297, '叭': 3298, '萱': 3299, '霾': 3300, '吝': 3301, '禺': 3302, '酋': 3303, '菇': 3304, '嗜': 3305, '襄': 3306, '蹊': 3307, '颤': 3308, '楷': 3309, '慑': 3310, '珏': 3311, '驯': 3312, '祷': 3313, '缇': 3314, '寇': 3315, '颂': 3316, '拽': 3317, '嫉': 3318, '憬': 3319, '氯': 3320, '飚': 3321, '褪': 3322, '氦': 3323, '灼': 3324, '眩': 3325, '悼': 3326, '螂': 3327, '俑': 3328, '咯': 3329, '铲': 3330, '砌': 3331, '疵': 3332, '兢': 3333, '跷': 3334, '枉': 3335, '袱': 3336, '晏': 3337, '皓': 3338, '澎': 3339, '晔': 3340, '僚': 3341, '・': 3342, '匈': 3343, '梓': 3344, '汛': 3345, '徕': 3346, '娴': 3347, '锥': 3348, '倚': 3349, '匮': 3350, '弩': 3351, '饽': 3352, '庇': 3353, '^': 3354, '厮': 3355, '荼': 3356, '匾': 3357, '沓': 3358, '恬': 3359, '瑾': 3360, '甫': 3361, '祺': 3362, '鳞': 3363, '孚': 3364, '眷': 3365, '孰': 3366, '坯': 3367, '孜': 3368, '迦': 3369, '莓': 3370, '拙': 3371, '矫': 3372, '僻': 3373, '啃': 3374, '蘑': 3375, '驴': 3376, '饺': 3377, '咽': 3378, '跋': 3379, '吟': 3380, '舵': 3381, '焚': 3382, '煽': 3383, '竿': 3384, '殴': 3385, '陇': 3386, '疤': 3387, '榆': 3388, '绊': 3389, '躬': 3390, '痪': 3391, '璧': 3392, '坷': 3393, '歹': 3394, '觑': 3395, '槟': 3396, '呐': 3397, '茸': 3398, '昱': 3399, '谬': 3400, '铨': 3401, '苞': 3402, '磕': 3403, '簿': 3404, '琥': 3405, '殆': 3406, '筝': 3407, '泻': 3408, '鞠': 3409, '缕': 3410, '窕': 3411, '窈': 3412, '檐': 3413, '兀': 3414, '掐': 3415, '趴': 3416, '瑙': 3417, '凛': 3418, '睦': 3419, '盏': 3420, '熄': 3421, '敷': 3422, '栅': 3423, '摒': 3424, '瞰': 3425, '潢': 3426, '喔': 3427, '佘': 3428, '蹿': 3429, '擒': 3430, '抒': 3431, '圭': 3432, '谙': 3433, '碘': 3434, '砥': 3435, '仆': 3436, '赃': 3437, '阪': 3438, '羹': 3439, '黏': 3440, '舅': 3441, '蹦': 3442, '鳍': 3443, '俘': 3444, '屉': 3445, '穹': 3446, '婪': 3447, '笈': 3448, '汲': 3449, '叨': 3450, '愣': 3451, '镍': 3452, '蛟': 3453, '挟': 3454, '撇': 3455, '咎': 3456, '寐': 3457, '°': 3458, '粥': 3459, '惮': 3460, '堰': 3461, '巍': 3462, '漩': 3463, '钙': 3464, '丐': 3465, '骋': 3466, '隋': 3467, '憨': 3468, '煜': 3469, '峨': 3470, '鹊': 3471, '毗': 3472, '慷': 3473, '酪': 3474, '哎': 3475, '烙': 3476, '\\\\': 3477, '棠': 3478, '娆': 3479, '慵': 3480, '挎': 3481, '莘': 3482, '煲': 3483, '惋': 3484, '咳': 3485, '翎': 3486, '尧': 3487, '寝': 3488, '斋': 3489, '昵': 3490, '蚕': 3491, '苯': 3492, '捣': 3493, '澈': 3494, '稠': 3495, '眨': 3496, '稣': 3497, '犷': 3498, '砷': 3499, '邃': 3500, '绞': 3501, '雏': 3502, '诧': 3503, '裘': 3504, '椭': 3505, '疟': 3506, '砭': 3507, '辫': 3508, '嘎': 3509, '呛': 3510, '涤': 3511, '篑': 3512, '榈': 3513, '岑': 3514, '戟': 3515, '颅': 3516, '铐': 3517, '咧': 3518, '蚓': 3519, '筷': 3520, '螃': 3521, '苟': 3522, '衅': 3523, '箍': 3524, '膺': 3525, '惶': 3526, '泵': 3527, '曳': 3528, '闽': 3529, '呱': 3530, '剽': 3531, '靶': 3532, '戳': 3533, '砝': 3534, '粟': 3535, '沽': 3536, '掺': 3537, '侥': 3538, '臻': 3539, '懵': 3540, '峙': 3541, '钵': 3542, '蝎': 3543, '狡': 3544, '弛': 3545, '昼': 3546, '琉': 3547, '碱': 3548, '哮': 3549, '奚': 3550, '伎': 3551, '蛰': 3552, '揪': 3553, '皙': 3554, '迸': 3555, '薯': 3556, '亢': 3557, '悖': 3558, '戎': 3559, '垦': 3560, '矜': 3561, '鸽': 3562, '鹦': 3563, '榕': 3564, '酣': 3565, '窒': 3566, '倔': 3567, '胯': 3568, '伶': 3569, '诵': 3570, '踵': 3571, '钊': 3572, '姊': 3573, '酌': 3574, '抨': 3575, '哟': 3576, '撩': 3577, '莅': 3578, 'μ': 3579, '拧': 3580, '®': 3581, '溉': 3582, '柠': 3583, '炅': 3584, '妓': 3585, '懿': 3586, '茧': 3587, '峭': 3588, '雁': 3589, '渎': 3590, '◎': 3591, '窖': 3592, '貂': 3593, '腩': 3594, '酥': 3595, '蒜': 3596, '舜': 3597, '蚯': 3598, '耘': 3599, '肴': 3600, '麓': 3601, '曜': 3602, '嚷': 3603, '韶': 3604, '娲': 3605, '缄': 3606, '嵩': 3607, '氓': 3608, '猬': 3609, '鹉': 3610, '娓': 3611, '敖': 3612, '诙': 3613, '筠': 3614, '刁': 3615, '匣': 3616, '矣': 3617, '邋': 3618, '柿': 3619, '※': 3620, '鱿': 3621, '紊': 3622, '淆': 3623, '皂': 3624, '竺': 3625, '鹜': 3626, '攘': 3627, '苓': 3628, '馅': 3629, '斓': 3630, '厥': 3631, '淌': 3632, '窜': 3633, '癖': 3634, '兮': 3635, '遢': 3636, '夭': 3637, '驹': 3638, '咪': 3639, '茎': 3640, '梗': 3641, '粽': 3642, '喋': 3643, '瑛': 3644, '屎': 3645, '鹭': 3646, '幔': 3647, '咀': 3648, '怠': 3649, '铧': 3650, '匡': 3651, '沌': 3652, '萤': 3653, '噢': 3654, '眈': 3655, '猖': 3656, '阙': 3657, '滇': 3658, '拌': 3659, '睫': 3660, '潍': 3661, '乒': 3662, '铂': 3663, '裱': 3664, '葫': 3665, '忡': 3666, '趸': 3667, '檬': 3668, '砺': 3669, '狩': 3670, '〈': 3671, '撬': 3672, '悸': 3673, '〉': 3674, '粱': 3675, '崽': 3676, '锏': 3677, '痊': 3678, '嚼': 3679, '瓢': 3680, '禹': 3681, '湮': 3682, '＝': 3683, '冗': 3684, '夯': 3685, '贰': 3686, '汝': 3687, '侮': 3688, '乓': 3689, '礴': 3690, '笃': 3691, '淤': 3692, '潞': 3693, '涎': 3694, '恪': 3695, '淼': 3696, '呦': 3697, '吆': 3698, '侄': 3699, '泓': 3700, '荔': 3701, '遴': 3702, '霓': 3703, '沂': 3704, '怯': 3705, '酵': 3706, '尉': 3707, '墩': 3708, '咫': 3709, '椰': 3710, '藩': 3711, '勺': 3712, '唾': 3713, '簧': 3714, '薰': 3715, '桓': 3716, '胧': 3717, '柒': 3718, '饕': 3719, '蠕': 3720, '钛': 3721, '蜒': 3722, '钰': 3723, '熹': 3724, '槌': 3725, '泾': 3726, '蜿': 3727, '埠': 3728, '疮': 3729, '谧': 3730, '挝': 3731, '笋': 3732, '瞿': 3733, '枣': 3734, '恺': 3735, '拂': 3736, '丫': 3737, '羌': 3738, '醍': 3739, '睾': 3740, '朦': 3741, '颚': 3742, '赈': 3743, '岌': 3744, '餮': 3745, '锷': 3746, '荟': 3747, '姝': 3748, '锄': 3749, '扉': 3750, '匕': 3751, '嘀': 3752, '芜': 3753, '铎': 3754, '萦': 3755, '暄': 3756, '秽': 3757, '栾': 3758, '啬': 3759, '菩': 3760, '糅': 3761, '鬃': 3762, '芋': 3763, '眸': 3764, '踞': 3765, '湃': 3766, '獗': 3767, '瀛': 3768, '裳': 3769, '奂': 3770, '纭': 3771, '罹': 3772, '焉': 3773, '阜': 3774, '氟': 3775, '茱': 3776, '瞅': 3777, '蛊': 3778, '昙': 3779, '篡': 3780, '蛤': 3781, '濮': 3782, '嵘': 3783, 'Ⅲ': 3784, '撮': 3785, '篱': 3786, '痞': 3787, '铿': 3788, '璞': 3789, '岔': 3790, '逞': 3791, '祀': 3792, '苇': 3793, '扒': 3794, '钝': 3795, '峪': 3796, '腱': 3797, '莽': 3798, '蚤': 3799, '溺': 3800, '瞠': 3801, '珐': 3802, '疚': 3803, '矗': 3804, '茬': 3805, '飒': 3806, '俺': 3807, '炖': 3808, '晾': 3809, '颊': 3810, '蒿': 3811, '橹': 3812, '彷': 3813, '咄': 3814, '泗': 3815, '掰': 3816, '笙': 3817, '砾': 3818, '卒': 3819, '沥': 3820, '宸': 3821, '馒': 3822, '嗽': 3823, '羲': 3824, '寅': 3825, '铠': 3826, '焱': 3827, '］': 3828, '螳': 3829, '铀': 3830, '漪': 3831, '遛': 3832, '荃': 3833, '浒': 3834, '姣': 3835, 'α': 3836, '诽': 3837, '聋': 3838, '猥': 3839, '丞': 3840, '［': 3841, '骰': 3842, '榨': 3843, '忱': 3844, '虱': 3845, '皿': 3846, '抠': 3847, '隼': 3848, '呗': 3849, '叱': 3850, '啼': 3851, '囱': 3852, '眯': 3853, '哉': 3854, '哼': 3855, '唉': 3856, '嚎': 3857, '憩': 3858, '嗒': 3859, '汾': 3860, '捅': 3861, '猾': 3862, '刨': 3863, '蟾': 3864, '鲶': 3865, '谤': 3866, '猝': 3867, '酯': 3868, '锌': 3869, '枭': 3870, '籽': 3871, '於': 3872, '犁': 3873, '曰': 3874, '垩': 3875, '唏': 3876, '诃': 3877, 'Ø': 3878, '①': 3879, '稼': 3880, '蜻': 3881, '唠': 3882, '™': 3883, '膛': 3884, '斟': 3885, '胤': 3886, 'è': 3887, '蟑': 3888, '轼': 3889, '痹': 3890, '叼': 3891, '猕': 3892, '蜓': 3893, '烬': 3894, '觎': 3895, '拣': 3896, '拗': 3897, '浚': 3898, '揍': 3899, '汕': 3900, '揉': 3901, '缮': 3902, '鄙': 3904, '剿': 3905, '泯': 3906, '祉': 3907, '璋': 3908, '虏': 3909, '婿': 3910, '莠': 3911, '捺': 3912, '蹬': 3913, '晦': 3914, '榷': 3915, '钒': 3916, '缨': 3917, '呜': 3918, '啪': 3919, '搀': 3920, '鹃': 3921, '狈': 3922, '觊': 3923, '瘟': 3924, '涓': 3925, '绌': 3926, '辍': 3927, '枷': 3928, '咤': 3929, '赣': 3930, '谛': 3931, '蔷': 3932, '腼': 3933, '亵': 3934, '浣': 3935, '〕': 3936, '霹': 3937, '饵': 3938, '瞥': 3939, '椋': 3940, '雳': 3941, '桔': 3942, '眶': 3943, '腆': 3944, '娩': 3945, '愫': 3946, '腮': 3947, '翌': 3948, '绢': 3949, '桨': 3950, '喙': 3951, '鞘': 3952, '旎': 3953, '〔': 3954, '惦': 3955, '凋': 3956, '澧': 3957, '憎': 3958, '惚': 3959, '烽': 3960, '跤': 3961, '昀': 3962, '殉': 3963, '怂': 3964, '邝': 3965, '涟': 3966, '芹': 3967, '魇': 3968, '羔': 3969, '贻': 3970, '祁': 3971, '赦': 3972, '殃': 3973, '蕊': 3974, '轲': 3975, '珉': 3976, '麾': 3977, '蟆': 3978, '驿': 3979, '咆': 3980, '蜍': 3981, '脐': 3982, '弋': 3983, '螈': 3984, '袒': 3985, '霁': 3986, '惰': 3987, '馥': 3988, '佯': 3989, '踹': 3990, '¾': 3991, '眺': 3992, '蓟': 3993, '祠': 3994, '渥': 3995, '掂': 3996, '臼': 3997, '蹭': 3998, '漾': 3999, '禀': 4000, '瘪': 4001, '喽': 4002, '涧': 4003, '懊': 4004, '鲟': 4005, '贮': 4006, '渍': 4007, '昴': 4008, '裆': 4009, '舔': 4010, 'ü': 4011, '摁': 4012, '琨': 4013, '谑': 4014, '咐': 4015, '钳': 4016, '缜': 4017, '昶': 4018, '摹': 4019, '帼': 4020, '焊': 4021, '毡': 4022, '‰': 4023, '锢': 4024, '邯': 4025, '②': 4026, '蛾': 4027, '髻': 4028, '秤': 4029, '肮': 4030, '蔑': 4031, '睽': 4032, '鬣': 4033, '茁': 4034, '涮': 4035, '町': 4036, '锚': 4037, '珞': 4038, '袄': 4039, '诩': 4040, '糜': 4041, '颌': 4042, '掮': 4043, '苔': 4044, '臆': 4045, '梧': 4046, '岖': 4047, '冽': 4048, '菠': 4049, '蔼': 4050, '黔': 4051, '诣': 4052, '镰': 4053, '膳': 4054, '殇': 4055, '漱': 4056, '躏': 4057, '垢': 4058, '坨': 4059, '腋': 4060, '鏖': 4061, '蹂': 4062, '泸': 4063, '铛': 4064, '札': 4065, '诘': 4066, '嗦': 4067, '玟': 4068, '偕': 4069, '妾': 4070, '嗡': 4071, '钚': 4072, '籁': 4073, '鹫': 4074, '搂': 4075, '澍': 4076, '隘': 4077, '卯': 4078, '迢': 4079, '馍': 4080, '遁': 4081, '袤': 4082, '炊': 4083, '溥': 4084, '嘶': 4085, '铤': 4086, '迂': 4087, '闰': 4088, '甭': 4089, '濡': 4090, '犒': 4091, '孽': 4092, '垣': 4093, '胫': 4094, '唬': 4095, 'Ａ': 4096, '胄': 4097, '嘈': 4098, '垡': 4099, '懦': 4100, '唧': 4101, '翱': 4102, '喃': 4103, '`': 4104, '跚': 4105, '晗': 4106, '棣': 4107, '荚': 4108, '幌': 4109, '⋯': 4110, '蹒': 4111, '殡': 4112, '犊': 4113, '蕙': 4114, '柚': 4115, '蛆': 4116, '茉': 4117, '煊': 4118, '冼': 4119, '遨': 4120, '涝': 4121, '胰': 4122, '哽': 4123, '馋': 4124, '睬': 4125, '馁': 4126, '鸠': 4127, '痫': 4128, '纣': 4129, '靳': 4130, '芥': 4131, '祛': 4132, '咂': 4133, '搓': 4134, '倭': 4135, '啄': 4136, '◇': 4137, '砰': 4138, '苷': 4139, '攫': 4140, '磺': 4141, '哆': 4142, '嗖': 4143, '浊': 4144, '榭': 4145, '恙': 4146, '涸': 4147, '霏': 4148, '扈': 4149, '獒': 4150, '搪': 4151, '酰': 4152, '鸳': 4153, '惭': 4154, '拄': 4155, '讧': 4156, '骅': 4157, '蜚': 4158, '鲤': 4159, '岱': 4160, '毓': 4161, '钠': 4162, '‧': 4163, '瞳': 4164, '潦': 4165, '藕': 4166, 'à': 4167, '芮': 4168, '脍': 4169, '濠': 4170, '疹': 4171, '偌': 4172, '啧': 4173, '镳': 4174, '嗣': 4175, '簸': 4176, '菅': 4177, '』': 4178, '狳': 4179, '阂': 4180, '『': 4181, '庶': 4182, '犰': 4183, '讹': 4184, '徨': 4185, '篆': 4186, '珥': 4187, '後': 4188, '鸯': 4189, '搡': 4190, '妊': 4191, '嫔': 4192, '梢': 4193, 'Ｇ': 4194, '掳': 4195, '瘩': 4196, '讥': 4197, '疙': 4198, '丕': 4199, '呃': 4200, '茗': 4201, '攸': 4202, '锲': 4203, '叩': 4204, '楔': 4205, '惘': 4206, '哩': 4207, '郦': 4208, '莺': 4209, '獭': 4210, '蹶': 4211, '衩': 4212, '↑': 4213, '夙': 4214, '虔': 4215, '嗔': 4216, '羸': 4217, '惴': 4218, '掣': 4219, '抡': 4220, '熨': 4221, '孪': 4222, '衙': 4223, '罡': 4224, '拈': 4225, '渭': 4226, 'Ｈ': 4227, '祟': 4228, '怅': 4229, '唆': 4230, '蔻': 4231, '恕': 4232, '狞': 4233, '愕': 4234, '啷': 4235, '燎': 4236, '瘠': 4237, '窿': 4238, '谩': 4239, '浜': 4240, '黝': 4241, '咔': 4242, '潺': 4243, 'Ⅶ': 4244, '涕': 4245, '纂': 4246, '箴': 4247, '遑': 4248, '靛': 4249, '藐': 4250, '煦': 4251, '踌': 4252, '邑': 4253, '▲': 4254, '咚': 4255, '魈': 4256, '婀': 4257, '湄': 4258, '筱': 4259, '鼬': 4260, '躇': 4261, '碾': 4262, '衢': 4263, '舛': 4264, '琶': 4265, '鸵': 4266, '泞': 4267, '轧': 4268, '拴': 4269, '撂': 4270, '攥': 4271, '忻': 4272, '√': 4273, '瘸': 4274, '佰': 4275, '铢': 4276, '翊': 4277, '裨': 4278, '腑': 4279, '漳': 4280, '胱': 4281, '馗': 4282, '讷': 4283, '徜': 4284, '灸': 4285, '跆': 4286, '祚': 4287, '樵': 4288, '珈': 4289, '―': 4290, '麂': 4291, '弑': 4292, '杞': 4293, '幄': 4294, '廿': 4295, '鳗': 4296, '鲑': 4297, '徉': 4298, '偎': 4299, '锵': 4300, '椁': 4301, '蛹': 4302, '冢': 4303, '娣': 4304, '侬': 4305, '笆': 4306, '③': 4307, '叽': 4308, '皑': 4309, '忏': 4310, '葩': 4311, '闳': 4312, '吱': 4313, '舷': 4314, '悴': 4315, '槐': 4316, '歆': 4317, '憔': 4318, '亘': 4319, 'Ⅰ': 4320, '蝌': 4321, '峦': 4322, '恣': 4323, '阑': 4324, '牒': 4325, '汞': 4326, '豉': 4327, '舸': 4328, '怵': 4329, '蝓': 4330, '蟠': 4331, '嗷': 4332, '帚': 4333, '盹': 4334, '褂': 4335, '蹴': 4336, '酗': 4337, '蚪': 4338, '噎': 4339, '灏': 4340, '蘸': 4341, '＆': 4342, '洱': 4343, '伫': 4344, '£': 4345, '甬': 4346, '〗': 4347, '↓': 4348, '掬': 4349, '〖': 4350, '淅': 4351, '贲': 4352, '懋': 4353, 'Ｃ': 4354, '蜷': 4355, '橇': 4356, '咙': 4357, '郸': 4358, '雹': 4359, '赓': 4360, '幺': 4361, '霰': 4362, '颦': 4363, '孱': 4364, '忒': 4365, '糗': 4366, '岷': 4367, '∩': 4368, '摞': 4369, '谚': 4370, '谲': 4371, '酮': 4372, '啮': 4373, '坂': 4374, '帛': 4375, '铱': 4376, '吒': 4377, '偃': 4378, '悯': 4379, '恻': 4380, '恿': 4381, 'β': 4382, 'Ｔ': 4383, '搔': 4384, '铯': 4385, '痰': 4386, '楹': 4387, '旖': 4388, '娠': 4389, '荥': 4390, '烩': 4391, '磐': 4392, '俚': 4393, '豌': 4394, '擞': 4395, '纫': 4396, '崴': 4397, '辘': 4398, '潸': 4399, '塾': 4400, '喳': 4401, '啻': 4402, '鎏': 4403, '狰': 4404, '壕': 4405, '颢': 4406, '嗤': 4407, '骛': 4408, '悻': 4409, '蛞': 4410, '嫡': 4411, '蚝': 4412, '焙': 4413, '糯': 4414, '缰': 4415, '鬓': 4416, '狒': 4417, '栎': 4418, '稔': 4419, '迩': 4420, '傀': 4421, '痘': 4422, '蔗': 4423, 'Ⅳ': 4424, '卞': 4425, '鹕': 4426, '蹩': 4427, '鹈': 4428, '孀': 4429, '瘀': 4430, '谕': 4431, '樾': 4432, '戾': 4433, '痼': 4434, '纾': 4435, '钿': 4436, '喱': 4437, '诬': 4438, '唔': 4439, '蛀': 4440, '钨': 4441, '滟': 4442, '楞': 4443, '拮': 4444, '栓': 4445, '粼': 4446, '骊': 4447, '壑': 4448, '濑': 4449, '仨': 4450, '￡': 4451, '嗨': 4452, '寮': 4453, '儡': 4454, '傣': 4455, '≠': 4456, '倜': 4457, '蕨': 4458, '吡': 4459, '霎': 4460, '疡': 4461, '泱': 4462, '羿': 4463, '俸': 4464, '瘙': 4465, '饬': 4466, '诿': 4467, '仝': 4468, '踉': 4469, '嗲': 4470, '柑': 4471, '纰': 4472, '腌': 4473, '嚏': 4474, '泠': 4475, '＞': 4476, '≤': 4477, '漕': 4478, '瓮': 4479, '聿': 4480, '腴': 4481, '喵': 4482, '卤': 4483, '箫': 4484, '樽': 4485, '褛': 4486, '惆': 4487, '渚': 4488, '羯': 4489, '摺': 4490, '酉': 4491, '挛': 4492, '氘': 4493, '傥': 4494, '笠': 4495, '幡': 4496, '诋': 4497, '鳖': 4498, '谒': 4499, '蚌': 4500, '炔': 4501, '屐': 4502, '奄': 4503, '谟': 4504, '羟': 4505, '飕': 4506, '鼹': 4507, '唰': 4508, '摈': 4509, '跄': 4510, '荀': 4511, '樨': 4512, '锆': 4513, '拚': 4514, '揄': 4515, '苜': 4516, '杵': 4517, '蓿': 4518, '盂': 4519, '麝': 4520, '镌': 4521, '揶': 4522, '阋': 4523, 'Ｏ': 4524, '鳃': 4525, '囡': 4526, '箔': 4527, '庾': 4528, '殓': 4529, '鸸': 4530, '蹋': 4531, '讪': 4532, '蝰': 4533, '脲': 4534, '阖': 4535, '稷': 4536, 'の': 4537, '褥': 4538, '胭': 4539, '铍': 4540, '桎': 4541, '疱': 4542, '潼': 4543, '绛': 4544, 'ä': 4545, '鲼': 4546, '诨': 4547, '梏': 4548, '逵': 4549, '铬': 4550, '痉': 4551, '鹋': 4552, '恃': 4553, '蔫': 4554, '钴': 4555, '铩': 4556, '皋': 4557, '§': 4558, 'Ｎ': 4559, '粕': 4560, '绫': 4561, '吭': 4562, '麽': 4563, '呻': 4564, '＊': 4565, '瞌': 4566, 'ン': 4567, '镣': 4568, '烊': 4569, '啕': 4570, '脓': 4571, '牍': 4572, '陲': 4573, '谘': 4574, '耷': 4575, '赅': 4576, '撷': 4577, '罔': 4578, '燮': 4579, '涣': 4580, '陂': 4581, '钜': 4582, '湍': 4583, '闾': 4584, '銮': 4585, '珙': 4586, '酩': 4587, '嚓': 4588, '邙': 4589, '怦': 4590, '铰': 4591, '忿': 4592, '＂': 4593, '祯': 4594, '榉': 4595, '刽': 4596, '伉': 4597, '蟀': 4598, '氚': 4599, '滦': 4600, '垠': 4601, '擘': 4602, '陛': 4603, '珩': 4604, '跺': 4605, '謦': 4606, '庖': 4607, '坻': 4608, '麋': 4609, '捶': 4610, '嗑': 4611, '褚': 4612, '焯': 4613, '湫': 4614, '僮': 4615, '桀': 4616, '荭': 4617, '蟋': 4618, '唁': 4619, '锹': 4620, '瘁': 4621, '咦': 4622, '熵': 4623, '榔': 4624, '胥': 4625, '腭': 4626, '缥': 4627, '桅': 4628, '嗝': 4629, '÷': 4630, '孺': 4631, '绉': 4632, '绥': 4633, '顼': 4634, '胛': 4635, 'É': 4636, '瞑': 4637, '砒': 4638, '颞': 4639, 'Ｂ': 4640, '脯': 4641, '噜': 4642, '荤': 4643, '吏': 4644, 'Ｅ': 4645, '囿': 4646, '骜': 4647, '捎': 4648, '沅': 4649, '瓯': 4650, '痍': 4651, '颛': 4652, '亳': 4653, '淄': 4654, '篝': 4655, '囔': 4656, '甥': 4657, '黠': 4658, '皖': 4659, '剁': 4660, '鞑': 4661, '秧': 4662, '娑': 4663, '谏': 4664, '吩': 4665, '赳': 4666, '撅': 4667, '鲈': 4668, '岫': 4669, '颧': 4670, '蹉': 4671, '岿': 4672, '谆': 4673, 'Ｄ': 4674, '跎': 4675, '漉': 4676, '佻': 4677, '\\xad': 4678, '仃': 4679, '²': 4680, '筵': 4681, '罂': 4682, '宦': 4683, '缈': 4684, '飨': 4685, '沣': 4686, '楣': 4687, '＜': 4688, '氩': 4689, '吮': 4690, '龈': 4691, '汩': 4692, '杳': 4693, '唳': 4694, '诏': 4695, '淞': 4696, '噔': 4697, '酚': 4698, '鼾': 4699, 'ó': 4700, '蛎': 4701, '锭': 4702, '鳕': 4703, 'イ': 4704, '碉': 4705, '蕲': 4706, '搐': 4707, '鄞': 4708, '臧': 4709, '皎': 4710, '诲': 4711, '蹑': 4712, '吠': 4713, '膘': 4714, '骡': 4715, '髋': 4716, '赡': 4717, '鹬': 4718, '艮': 4719, 'Ｖ': 4720, '楦': 4721, '＇': 4722, '嫖': 4723, '婶': 4724, '轫': 4725, '蛭': 4726, '€': 4727, '盥': 4728, '疣': 4729, '琵': 4730, '掴': 4731, '倬': 4732, '咿': 4733, '碴': 4734, '癣': 4735, '泔': 4736, '榫': 4737, '汨': 4738, 'ル': 4739, '蝾': 4740, '岬': 4741, '敝': 4742, '芊': 4743, '龛': 4744, '氙': 4745, '耦': 4746, '踱': 4747, '褓': 4748, '笺': 4749, '镉': 4750, '戊': 4751, '斡': 4752, '叁': 4753, '抿': 4754, '荞': 4755, '蚩': 4756, '袅': 4757, '婵': 4758, '徇': 4759, 'Ｆ': 4760, '仟': 4761, '皈': 4762, '逯': 4763, 'Ｓ': 4764, '彝': 4765, '讴': 4766, '醺': 4767, '柩': 4768, '炕': 4769, '淖': 4770, '揆': 4771, '綦': 4772, '畿': 4773, '嘞': 4774, '俾': 4775, '鲇': 4776, '狨': 4777, '芾': 4778, '蓦': 4779, '锶': 4780, '噤': 4781, '琏': 4782, '｜': 4783, '锰': 4784, '镪': 4785, '琮': 4786, '菏': 4787, '鲵': 4788, '掖': 4789, '璎': 4790, '荻': 4791, '韭': 4792, 'Ｐ': 4793, '鲔': 4794, '葳': 4795, 'ア': 4796, '嘹': 4797, '觞': 4798, '洙': 4799, '秣': 4800, '庵': 4801, '烃': 4802, '徵': 4803, '肽': 4804, '殒': 4805, '兖': 4806, '璜': 4807, '」': 4808, '龅': 4809, '啶': 4810, 'ç': 4811, '裥': 4812, '跛': 4813, '缂': 4814, '獠': 4815, '「': 4816, '袢': 4817, '莆': 4818, '豺': 4819, '勐': 4820, '妲': 4821, '磬': 4822, '浔': 4823, '睑': 4824, '鲱': 4825, '箩': 4826, '碜': 4827, '驮': 4828, '犄': 4829, '堑': 4830, '嬗': 4831, '蝮': 4832, '滢': 4833, '捱': 4834, '哌': 4835, '鹳': 4836, '圩': 4837, '叻': 4838, '锟': 4839, '栉': 4840, 'γ': 4841, '靼': 4842, '樘': 4843, '涔': 4844, '棂': 4845, '沱': 4846, '鸢': 4847, '馏': 4848, '苒': 4849, '颉': 4850, '桢': 4851, '隍': 4852, '牦': 4853, '瓒': 4854, '擢': 4855, '郇': 4856, '暌': 4857, '蜇': 4858, '劾': 4859, '≥': 4860, '捋': 4861, '扪': 4862, '邛': 4863, '蝗': 4864, '镭': 4865, '嵋': 4866, '桉': 4867, '捻': 4868, 'ö': 4869, 'ラ': 4870, '褴': 4871, '娼': 4872, '仄': 4873, '濂': 4874, '\\uf06c': 4875, '淬': 4876, '枳': 4877, '枸': 4878, '峋': 4879, '阉': 4880, '疽': 4881, '襁': 4882, '秸': 4883, '螨': 4884, '骞': 4885, '芷': 4886, '榛': 4887, '颀': 4888, '莨': 4889, '秆': 4890, '藓': 4891, '蕃': 4892, '悱': 4893, '旮': 4894, '窠': 4895, '溧': 4896, '嶙': 4897, 'ス': 4898, '}': 4899, '崂': 4900, '湎': 4901, '藜': 4902, '鸩': 4903, '钌': 4904, '椿': 4905, 'Ⅵ': 4906, '邡': 4907, '锗': 4908, '郴': 4909, '桁': 4910, '洵': 4911, '醴': 4912, 'Ｍ': 4913, '赭': 4914, '墒': 4915, '坳': 4916, '醚': 4917, 'ジ': 4918, '簪': 4919, '踮': 4920, '儆': 4921, '隈': 4922, 'Ｘ': 4923, '岘': 4924, '肛': 4925, '氪': 4926, '谶': 4927, '痤': 4928, '耆': 4929, '骧': 4930, '囹': 4931, '岙': 4932, '螭': 4933, '螯': 4934, '缱': 4935, '澹': 4936, '谔': 4937, '醪': 4938, '厝': 4939, '圄': 4940, '旯': 4941, '啖': 4942, '蜃': 4943, '鸾': 4944, '④': 4945, '梆': 4946, 'í': 4947, '硒': 4948, '绺': 4949, 'ê': 4950, '睇': 4951, '芑': 4952, '砧': 4953, '钤': 4954, '戬': 4955, '玷': 4956, '晌': 4957, '跗': 4958, '\\u200b': 4959, 'á': 4960, '嶂': 4961, '钺': 4962, '泷': 4963, '瓴': 4964, '痨': 4965, '耙': 4966, '±': 4967, '郗': 4968, '睢': 4969, '怆': 4970, '弼': 4971, 'Ⅷ': 4972, '挞': 4973, '纨': 4974, '┊': 4975, '孑': 4976, '俎': 4977, '戍': 4978, '″': 4979, '噼': 4980, '氤': 4981, '涪': 4982, '绗': 4983, '撵': 4984, '倌': 4985, '荏': 4986, '遽': 4987, '蜈': 4988, '＃': 4989, '箕': 4990, '竽': 4991, '钯': 4992, '韪': 4993, '貔': 4994, '凼': 4995, '箐': 4996, '垭': 4997, '枥': 4998, '貅': 4999}\n","x_train= [[1609  659   56 ...    9  311    3]\n"," [   2  101   16 ... 1168    3   24]\n"," [ 465  855  521 ...  116  136   85]\n"," ...\n"," [  49   18   79 ...  836 1928 1072]\n"," [ 166  110  714 ...  836 1928 1072]\n"," [   1   80  551 ...   78  192    3]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RfFL0lTCkjxK","colab_type":"code","colab":{}},"source":["# TextRNN Model\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n"," \n","# 文本分类，RNN模型\n","class TextRNN(nn.Module):   \n","    def __init__(self):\n","        super(TextRNN, self).__init__()\n","        # 进行词嵌入\n","        self.embedding = nn.Embedding(5000, 64)  \n","        # self.rnn = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n","        self.rnn = nn.GRU(input_size=64, hidden_size=128, num_layers=2, bidirectional=True)\n","        self.f1 = nn.Sequential(nn.Linear(256,128),\n","                                nn.Dropout(0.8),\n","                                nn.ReLU())\n","        self.f2 = nn.Sequential(nn.Linear(128,10),\n","                                nn.Softmax())\n"," \n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x,_ = self.rnn(x)\n","        x = F.dropout(x,p=0.8)\n","        x = self.f1(x[:,-1,:])\n","        return self.f2(x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aQ_J-6A7AO2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"50be9b7d-7c3c-4713-be56-c7b1b66a87e9","executionInfo":{"status":"ok","timestamp":1589294659319,"user_tz":-480,"elapsed":1462591,"user":{"displayName":"Mary Miller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp5B0q3ZMIgJqiyxVfsSNo_frsANO1M6xCbz24=s64","userId":"00211487820884275324"}}},"source":["import torch\n","from torch import nn\n","from torch import optim\n","import numpy as np\n","#from model import TextRNN\n","#from cnews_loader import read_category, read_vocab, process_file\n","import torch.utils.data as Data #将数据分批次需要用到\n","import matplotlib.pyplot as plt\n","\n","train_file = 'cnews.train.txt'\n","test_file = 'cnews.test.txt'\n","val_file = 'cnews.val.txt'\n","vocab_file = 'cnews.vocab.txt'\n","\n","train_loss = []\n","val_loss = []\n","train_acc = []\n","val_acc = []\n","\n","cuda = torch.device('cuda')\n","\n","def display_training_curves(training, validation, title, subplot):\n","    if subplot%10==1: # set up the subplots on the first call # 在第一次调用该函数时设置子图\n","        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n","        plt.tight_layout()\n","    ax = plt.subplot(subplot) #设置子图\n","    ax.set_facecolor('#F8F8F8') #设置背景颜色\n","    ax.plot(training) #画训练集的曲线\n","    ax.plot(validation) #画测试集的曲线\n","    ax.set_title('model '+ title)\n","    ax.set_ylabel(title) #设置y轴标题\n","    #ax.set_ylim(0.28,1.05)\n","    ax.set_xlabel('epoch') #设置x轴标题\n","    ax.legend(['train', 'valid.']) #设置图例\n","    plt.savefig(\"model.png\")\n","\n","def train():\n","  #使用TextRNN\n","  model = TextRNN().cuda()\n","  #损失函数\n","  Loss = nn.MultiLabelSoftMarginLoss()\n","  optimizer = optim.Adam(model.parameters(), lr=0.01)\n","  best_val_acc = 0\n","  for epoch in range(20):\n","    print('epoch:', epoch+1)\n","    for step, (x_batch, y_batch) in enumerate(train_loader):\n","      x = x_batch.cuda()\n","      y = y_batch.cuda()\n","      out = model(x)\n","      loss = Loss(out, y)\n","      print('loss=', loss)\n","      train_loss.append(loss)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      #计算准确率\n","      accuracy = np.mean((torch.argmax(out,1) == torch.argmax(y,1)).cpu().numpy())\n","      print('accuracy=', accuracy)\n","      train_acc.append(accuracy)\n","      #对模型进行验证\n","      if (epoch+1)%2 == 0:\n","        with torch.no_grad():\n","          for step, (x_batch, y_batch) in enumerate(val_loader):\n","            x = x_batch.cuda()\n","            y = y_batch.cuda()\n","            out = model(x)\n","            loss_val = Loss(out, y)\n","            val_loss.append(loss_val)\n","            accuracy = np.mean((torch.argmax(out,1) == torch.argmax(y,1)).cpu().numpy())\n","            val_acc.append(accuracy)\n","            if accuracy > best_val_acc:\n","              torch.save(model.state_dict(), 'model_params.pkl')\n","              best_val_acc = accuracy\n","              print('val_accuracy=', accuracy)\n","  display_training_curves(train_loss, val_loss, 'loss', 211)\n","  display_training_curves(train_acc, val_acc, 'acc', 212)\n","\n","if __name__==\"__main__\":\n","\t# 获取文本的类别及其对应id的字典\n","\tcategories, cat_to_id = read_category()\n","\t#print(categories)\n","\t# 获取训练文本中所有出现过的字及其所对应的id\n","\twords, word_to_id = read_vocab('./code/cnews/cnews.vocab.txt')\n","\t#print(words)\n","\t#print(word_to_id)\n","\t#print(word_to_id)\n","\t#获取字数\n","\tvocab_size = len(words)\n","\n","\t# 数据加载及分批\n","\t# 获取训练数据每个字的id和对应标签的one-hot形式\n","\tx_train, y_train = process_file('./code/cnews/cnews.train.txt', word_to_id, cat_to_id, 600)\n","\tprint('x_train=', x_train)\n","\tx_val, y_val = process_file('./code/cnews/cnews.val.txt', word_to_id, cat_to_id, 600)\n","\n","\tx_train, y_train = torch.LongTensor(x_train), torch.Tensor(y_train)\n","\tx_val, y_val = torch.LongTensor(x_val), torch.Tensor(y_val)\n","\n","\t#数据分批\n","\ttrain_dataset = Data.TensorDataset(x_train, y_train)\n","\ttrain_loader = Data.DataLoader(dataset=train_dataset, batch_size=500, shuffle=True, num_workers=2)\n","\n","\tval_dataset = Data.TensorDataset(x_val, y_val)\n","\tval_loader = Data.DataLoader(dataset=val_dataset, batch_size=500, shuffle=True, num_workers=2)\n","\t\n","\ttrain()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["x_train= [[1609  659   56 ...    9  311    3]\n"," [   2  101   16 ... 1168    3   24]\n"," [ 465  855  521 ...  116  136   85]\n"," ...\n"," [  49   18   79 ...  836 1928 1072]\n"," [ 166  110  714 ...  836 1928 1072]\n"," [   1   80  551 ...   78  192    3]]\n","epoch: 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"},{"output_type":"stream","text":["loss= tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.12\n","loss= tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.09\n","loss= tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.108\n","loss= tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.142\n","loss= tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.21\n","loss= tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.224\n","loss= tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.23\n","loss= tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.27\n","loss= tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.268\n","loss= tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.286\n","loss= tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.284\n","loss= tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.288\n","loss= tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.292\n","loss= tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7209, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.294\n","loss= tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.276\n","loss= tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.272\n","loss= tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.286\n","loss= tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.294\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.284\n","loss= tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.294\n","loss= tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","loss= tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","loss= tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.302\n","loss= tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7212, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.29\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.302\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.286\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.294\n","loss= tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.292\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.29\n","loss= tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.296\n","loss= tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.282\n","loss= tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.296\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.302\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.296\n","loss= tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","epoch: 2\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","val_accuracy= 0.268\n","val_accuracy= 0.33\n","val_accuracy= 0.346\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","val_accuracy= 0.348\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","val_accuracy= 0.35\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","val_accuracy= 0.356\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.296\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.286\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.296\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","val_accuracy= 0.362\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","val_accuracy= 0.364\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","val_accuracy= 0.376\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.426\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","val_accuracy= 0.38\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","val_accuracy= 0.392\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.3\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","epoch: 3\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","epoch: 4\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.412\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.302\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","epoch: 5\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.3\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","epoch: 6\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.41\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","epoch: 7\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.414\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7104, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.408\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.414\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","epoch: 8\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.412\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.302\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.41\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","val_accuracy= 0.416\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.416\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","epoch: 9\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.426\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.298\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.424\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","epoch: 10\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.414\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","epoch: 11\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.294\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.416\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","epoch: 12\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.292\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","epoch: 13\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.418\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","epoch: 14\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.408\n","loss= tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.408\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.31\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.29\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","epoch: 15\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.442\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","epoch: 16\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.428\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.4\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.408\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","epoch: 17\n","loss= tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.304\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.412\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","epoch: 18\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.382\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.408\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.41\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.386\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.398\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","epoch: 19\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.412\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.308\n","loss= tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.312\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.396\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.402\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.35\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.33\n","loss= tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.324\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.316\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.406\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.404\n","loss= tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n","loss= tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","epoch: 20\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.364\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.424\n","loss= tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.388\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.392\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.344\n","loss= tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.358\n","loss= tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.41\n","loss= tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.374\n","loss= tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.326\n","loss= tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.336\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.332\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.366\n","loss= tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.318\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.376\n","loss= tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.306\n","loss= tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.38\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.342\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.36\n","loss= tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.338\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.328\n","loss= tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.39\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.334\n","loss= tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.348\n","loss= tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.368\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.394\n","loss= tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.314\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.32\n","loss= tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.34\n","loss= tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.352\n","loss= tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.378\n","loss= tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.37\n","loss= tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.322\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.362\n","loss= tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.384\n","loss= tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.356\n","loss= tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.372\n","loss= tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.354\n","loss= tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n","accuracy= 0.346\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5f6WgwjtFHe2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"3b7cc9f9-6e3b-4de4-e3a3-21991b6cc72d","executionInfo":{"status":"ok","timestamp":1589296407902,"user_tz":-480,"elapsed":3646,"user":{"displayName":"Mary Miller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp5B0q3ZMIgJqiyxVfsSNo_frsANO1M6xCbz24=s64","userId":"00211487820884275324"}}},"source":["import keras as kr\n","import torch\n","from torch import nn\n","#from cnews_loader import read_category, read_vocab\n","#from model import TextRNN\n","import numpy as np\n"," \n","vocab_file = './code/cnews/cnews.vocab.txt'\n"," \n","class RnnModel:\n","    def __init__(self):\n","        self.categories, self.cat_to_id = read_category()\n","        self.words, self.word_to_id = read_vocab(vocab_file)\n","        self.model = TextRNN()\n","        self.model.load_state_dict(torch.load('model_params.pkl'))\n"," \n","    def predict(self, message):\n","        content = message\n","        data = [self.word_to_id[x] for x in content if x in self.word_to_id]\n","        data = kr.preprocessing.sequence.pad_sequences([data], 600)\n","        data = torch.LongTensor(data)\n","        y_pred_cls = self.model(data)\n","        class_index = torch.argmax(y_pred_cls[0]).item()\n","        return self.categories[class_index]\n"," \n"," \n","if __name__ == '__main__':\n","    model = RnnModel()\n","    test_demo = ['《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437']\n","                 \n","    for i in test_demo:\n","      print(i,\":\",model.predict(i))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437 : 游戏\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"}]}]}